import os
import time
import psycopg2
import logging
import requests
import librosa
import shutil
import subprocess
import json
import openai
from contextlib import contextmanager
from typing import Optional, List

import soundfile as sf  # íƒ€ì„ ìŠ¤íŠ¸ë ˆì¹­ í›„ ì˜¤ë””ì˜¤ ì €ì¥ìš©
import tensorflow as tf
from fastapi import FastAPI, UploadFile, File, HTTPException, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from pydub import AudioSegment
from pydub.silence import detect_nonsilent
from spleeter.separator import Separator


# ----------------------------
# ê¸°ë³¸ ì„¤ì • ë° í™˜ê²½ ë³€ìˆ˜
# ----------------------------
logging.basicConfig(level=logging.DEBUG)

AUDIO_FOLDER = "extracted_audio"
os.makedirs(AUDIO_FOLDER, exist_ok=True)
CUSTOM_TTS_FOLDER = os.path.join(AUDIO_FOLDER, "custom_tts")
os.makedirs(CUSTOM_TTS_FOLDER, exist_ok=True)
VOICE_MODEL_FOLDER = "voice_models"
os.makedirs(VOICE_MODEL_FOLDER, exist_ok=True)
USER_FILES_FOLDER = "user_files"
os.makedirs(USER_FILES_FOLDER, exist_ok=True)

# FastAPI ì•± ìƒì„±
app = FastAPI()

DB_NAME = "test"
DB_USER = "postgres"
DB_PASSWORD = "1234"
DB_HOST = "localhost"
DB_PORT = "5433"

ELEVENLABS_API_KEY = "eleven-keyf"
ELEVENLABS_BASE_URL = "https://api.elevenlabs.io/v1"

# OpenAI API ì„¤ì • (ë²ˆì—­ìš©)
OPENAI_API_KEY = "gpt-key"
openai.api_key = OPENAI_API_KEY

# â”€â”€ NEW: ì–¸ì–´ë³„ í‰ê·  ì½ê¸° ì†ë„ (ìŒì ˆ/ë¬¸ì per sec)
AVG_SYL_PER_SEC = {"ko": 6.2, "en": 6.19, "ja": 7.84, "zh": 5.18}
TOL_RATIO = 0.02
MIN_SENT_LEN = 4
SUPPORTED_LANGS = set(AVG_SYL_PER_SEC)  # {'ko','en','ja','zh'}

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ----------------------------
# Pydantic ëª¨ë¸
# ----------------------------
class CustomTTSRequest(BaseModel):
    tts_id: Optional[int] = None
    voice_id: str
    text: str

# ----------------------------
# PostgreSQL ì—°ê²° í•¨ìˆ˜
# ----------------------------
def get_connection():
    conn = psycopg2.connect(
        dbname=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD,
        host=DB_HOST,
        port=DB_PORT
    )
    return conn

@contextmanager
def get_db_cursor():
    conn = get_connection()
    try:
        curs = conn.cursor()
        yield curs
        conn.commit()
    except Exception as e:
        conn.rollback()
        raise e
    finally:
        curs.close()
        conn.close()

# ----------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ----------------------------
def ensure_folder(path: str):
    os.makedirs(path, exist_ok=True)

def delete_temp_files(file_paths: List[str]):
    for fp in file_paths:
        try:
            if os.path.exists(fp):
                if os.path.isdir(fp):
                    shutil.rmtree(fp, ignore_errors=True)
                    logging.info(f"Deleted folder: {fp}")
                else:
                    os.remove(fp)
                    logging.info(f"Deleted file: {fp}")
        except Exception as e:
            logging.error(f"Failed to delete {fp}: {e}")

# â€• NEW: í•œê¸€ ìŒì ˆ/ë¬¸ì ìˆ˜ ì„¸ê¸°
def count_units(txt: str, lang: str) -> int:
    if lang == "ko":
        return sum('\uAC00' <= c <= '\uD7A3' for c in txt)
    return len(txt)

# â€• NEW: ê¸¸ì´-ì˜ì‹ ë²ˆì—­ í•¨ìˆ˜
def translate_length_aware(
    src_text: str,
    src_lang: str,
    tgt_lang: str,
    dur_sec: float,
    voice_id: str,
    db_cursor,
    retries: int = 4,
):
    tgt = tgt_lang[:2]

    cps     = get_cps(db_cursor, voice_id, tgt)      # ë³´ì´ìŠ¤-ì–¸ì–´ ê¸€ì/ì´ˆ
    target  = int(dur_sec * cps)                     # ëª©í‘œ ê¸€ì ìˆ˜
    tol     = max(2, round(target * TOL_RATIO))       # Â±2% (ìµœì†Œ 2ê¸€ì)
    lo, hi  = target - tol, target + tol
    unit    = "Hangul syllables" if tgt == "ko" else "characters"

    goal = target                                    # â¬…ï¸ â‘  ì²« ëª©í‘œê°’
    for _ in range(retries):
        sys_msg = (
            f"Translate from {src_lang[:2]} to {tgt}. "
            f"Make the output **exactly {goal} {unit}** long. "
            "Translate faithfullyâ€”KEEP all proper nouns; do NOT summarize."
        )
        res = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": sys_msg},
                      {"role": "user",   "content": src_text}],
        ).choices[0].message.content.strip()

        n = count_units(res, tgt)
        if lo <= n <= hi:           # âœ… í—ˆìš© ë²”ìœ„ ì•ˆì´ë©´ ë°˜í™˜
            return res

        # â¬‡ï¸ ê¸¸ê±°ë‚˜ ì§§ìœ¼ë©´ ëª©í‘œ ê¸€ììˆ˜ë¥¼ 1ì”© ì¡°ì •
        if n > hi:
            goal -= 1
        else:      # n < lo
            goal += 1
        goal = max(MIN_SENT_LEN, goal)   # ìµœì†Œ ê¸¸ì´ ë³´ì¥

    return res   # ë§ˆì§€ë§‰ ì‹œë„ë¼ë„ ë°˜í™˜

# â€• Stretch (Â±3 % ì´ë‚´)
def stretch_audio(input_path: str, output_path: str, current_duration: float, desired_duration: float) -> float:
    speed = current_duration / desired_duration
    speed = max(0.97, min(1.03, speed))  # Â±3 %
    logging.debug(f"Speed change {speed:.3f}Ã—")

    sound = AudioSegment.from_file(input_path)
    new_fr = int(sound.frame_rate * speed)
    stretched = sound._spawn(sound.raw_data, overrides={"frame_rate": new_fr})
    stretched = stretched.set_frame_rate(sound.frame_rate)
    ensure_folder(os.path.dirname(output_path))
    stretched.export(output_path, format="mp3", bitrate="192k")
    return len(stretched) / 1000.0

def run_spleeter_subprocess(input_path: str, output_folder: str):
    command = [
        "python", "-m", "spleeter.separator",
        "separate_to_file", input_path, output_folder,
        "-p", "spleeter:2stems"
    ]
    logging.info("Spleeter subprocess command: " + " ".join(command))
    result = subprocess.run(command, capture_output=True, text=True)
    if result.returncode != 0:
        raise Exception("Spleeter subprocess failed: " + result.stderr)
    else:
        logging.info(result.stdout)

def find_spleeter_vocals(base_folder: str, base_name: str):
    vocals_candidates = []
    bgm_candidates = []
    primary_folder = os.path.join(base_folder, base_name)
    if os.path.exists(primary_folder):
        for root, dirs, files in os.walk(primary_folder):
            if "vocals.wav" in files:
                vocals_candidates.append(os.path.join(root, "vocals.wav"))
            if "accompaniment.wav" in files:
                bgm_candidates.append(os.path.join(root, "accompaniment.wav"))
    alternate_folder = os.path.join(base_folder, f"{base_name}_audio")
    if os.path.exists(alternate_folder):
        for root, dirs, files in os.walk(alternate_folder):
            if "vocals.wav" in files:
                vocals_candidates.append(os.path.join(root, "vocals.wav"))
            if "accompaniment.wav" in files:
                bgm_candidates.append(os.path.join(root, "accompaniment.wav"))
    if not vocals_candidates or not bgm_candidates:
        raise FileNotFoundError(
            f"âŒ '{base_folder}' ë‚´ì— '{base_name}' ë˜ëŠ” '{base_name}_audio' í´ë”ì—ì„œ í•„ìš”í•œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!"
        )
    # ì—¬ëŸ¬ ê°œ ìˆë”ë¼ë„ ì²« ë²ˆì§¸ í•­ëª©ë§Œ ì„ íƒí•´ì„œ ë°˜í™˜
    return vocals_candidates[0], bgm_candidates[0]


def split_audio(input_path: str, output_dir: str, max_size_mb: int = 10):
    ensure_folder(output_dir)
    try:
        audio = AudioSegment.from_file(input_path)
        threshold = audio.dBFS - 16
        nonsilent_ranges = detect_nonsilent(audio, min_silence_len=500, silence_thresh=threshold, seek_step=1)
        parts = []
        for idx, (start, end) in enumerate(nonsilent_ranges):
            if end - start < 1000:
                continue
            segment = audio[start:end]
            part_path = os.path.join(output_dir, f"part_{idx}.mp3")
            segment.export(part_path, format="mp3", bitrate="192k")
            parts.append(part_path)
        logging.info(f"ğŸ”¹ ë¶„í• ëœ íŒŒì¼ ê°œìˆ˜: {len(parts)}")
        max_samples = 25
        if len(parts) > max_samples:
            indices = [int(i * (len(parts) - 1) / (max_samples - 1)) for i in range(max_samples)]
            parts = [parts[i] for i in indices]
            logging.info(f"ğŸ”¹ ìƒ˜í”Œ ìˆ˜ê°€ ë§ì•„ ê· ì¼í•˜ê²Œ {max_samples}ê°œë¡œ ì¶•ì†Œí•¨")
        return parts
    except Exception as e:
        logging.error(f"âŒ ì˜¤ë””ì˜¤ ë¶„í•  ì‹¤íŒ¨: {str(e)}")
        return []

def merge_nonsilent_audio_improved(
    input_path: str,
    output_dir: str,
    min_silence_len: int = 500,
    silence_thresh: float = None,
    output_filename: str = "merged_sample.mp3",
    fade_duration: int = 200
):
    ensure_folder(output_dir)
    try:
        audio = AudioSegment.from_file(input_path)
        if silence_thresh is None:
            silence_thresh = audio.dBFS - 16
        nonsilent_ranges = detect_nonsilent(
            audio,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh,
            seek_step=1
        )
        merged_audio = AudioSegment.empty()
        for start, end in nonsilent_ranges:
            if end - start < 1000:
                continue
            segment = audio[start:end]
            segment = segment.fade_in(fade_duration).fade_out(fade_duration)
            merged_audio += segment
        output_path = os.path.join(output_dir, output_filename)
        merged_audio.export(output_path, format="mp3", bitrate="192k")
        logging.info(f"ğŸ”¹ ë³‘í•©ëœ íŒŒì¼ ìƒì„±: {output_path}")
        return output_path
    except Exception as e:
        logging.error(f"âŒ ë³‘í•© ì‹¤íŒ¨: {str(e)}")
        return None

def split_merged_audio(
    merged_path: str,
    output_dir: str,
    max_duration_sec: int = 30,
    max_samples: int = 25
):
    ensure_folder(output_dir)
    try:
        audio = AudioSegment.from_file(merged_path)
        duration_ms = len(audio)
        max_duration_ms = max_duration_sec * 1000
        parts = []
        if duration_ms <= max_duration_ms:
            parts.append(merged_path)
        else:
            num_parts = (duration_ms + max_duration_ms - 1) // max_duration_ms
            for i in range(num_parts):
                start = i * max_duration_ms
                end = min((i + 1) * max_duration_ms, duration_ms)
                segment = audio[start:end]
                part_path = os.path.join(output_dir, f"merged_part_{i}.mp3")
                segment.export(part_path, format="mp3", bitrate="192k")
                parts.append(part_path)
        if len(parts) > max_samples:
            indices = [
                int(i * (len(parts) - 1) / (max_samples - 1))
                for i in range(max_samples)
            ]
            parts = [parts[i] for i in indices]
            logging.info(f"ğŸ”¹ ë³‘í•© ìƒ˜í”Œ ìˆ˜ê°€ ë§ì•„ ê· ì¼í•˜ê²Œ {max_samples}ê°œë¡œ ì¶•ì†Œí•¨")
        return parts
    except Exception as e:
        logging.error(f"âŒ ë³‘í•© í›„ ë¶„í•  ì‹¤íŒ¨: {str(e)}")
        return []

def create_voice_model_api(name: str, description: str, sample_file_paths: List[str]):
    url = f"{ELEVENLABS_BASE_URL}/voices/add"
    headers = {"xi-api-key": ELEVENLABS_API_KEY}
    data = {"name": name, "description": description}
    files = []
    for path in sample_file_paths:
        try:
            f = open(path, "rb")
        except Exception as e:
            logging.error(f"íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨ ({path}): {str(e)}")
            continue
        files.append(("files", (os.path.basename(path), f, "audio/mpeg")))
    try:
        response = requests.post(url, headers=headers, data=data, files=files)
        response.raise_for_status()
        return response.json()
    finally:
        for _, file_tuple in files:
            file_tuple[1].close()

def adjust_tts_duration(file_path: str, desired_duration: float) -> float:
    y, sr = librosa.load(file_path, sr=None)
    current_duration = librosa.get_duration(y=y, sr=sr)
    rate = current_duration / desired_duration
    rate = min(max(rate, 0.9), 1.1)
    logging.info(
        f"adjust_tts_duration - í˜„ì¬ ê¸¸ì´: {current_duration:.2f} sec, "
        f"ì›í•˜ëŠ” ê¸¸ì´: {desired_duration:.2f} sec, ì ìš© ë¹„ìœ¨: {rate:.2f}"
    )
    y_stretched = librosa.effects.time_stretch(y, rate=rate)
    sf.write(file_path, y_stretched, sr)
    new_duration = librosa.get_duration(y=y_stretched, sr=sr)
    logging.info(f"adjust_tts_duration - ì¡°ì • í›„ ê¸¸ì´: {new_duration:.2f} sec")
    return new_duration


# ----------------------------
# FastAPI ì—”ë“œí¬ì¸íŠ¸
# ----------------------------
app.mount("/uploaded_videos", StaticFiles(directory="uploaded_videos"), name="videos")
app.mount("/extracted_audio", StaticFiles(directory="extracted_audio"), name="audio")

@app.get("/")
def read_root():
    return {"message": "Hello from Service B (TTS Creation)!"}

@app.post("/separate-audio")
async def separate_audio(file: UploadFile = File(...)):
    try:
        original_name = os.path.splitext(file.filename)[0]
        base_name = (
            original_name[:-len("_audio")]
            if file.filename.endswith("_audio")
            else original_name
        )
        input_path = os.path.join(AUDIO_FOLDER, f"{base_name}.mp3")
        with open(input_path, "wb") as f:
            f.write(await file.read())
        logging.info(f"ì…ë ¥ ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {input_path}")

        from spleeter.separator import Separator
        separator = Separator("spleeter:2stems")
        separator.separate_to_file(input_path, AUDIO_FOLDER)
        logging.info("Spleeter ë¶„ë¦¬ ì‹¤í–‰ ì™„ë£Œ")

        vocals_path, bgm_path = find_spleeter_vocals(AUDIO_FOLDER, base_name)
        logging.info(f"ë¶„ë¦¬ëœ íŒŒì¼ ì°¾ìŒ: vocals={vocals_path}, bgm={bgm_path}")

        return JSONResponse(
            content={
                "message": "Spleeter ë¶„ë¦¬ ì™„ë£Œ",
                "vocals_path": vocals_path,
                "bgm_path": bgm_path
            },
            status_code=200
        )
    except Exception as e:
        logging.error(f"Spleeter ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"Spleeter ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
        )
        
def stretch_audio(input_path: str, output_path: str, current_duration: float, desired_duration: float) -> float:
    """
    pydubì„ ì‚¬ìš©í•´ íŒŒì¼ ì†ë„ë¥¼ ì¡°ì ˆ.
    Returns: ìƒˆë¡œ ì¡°ì •ëœ ê¸¸ì´ (ì´ˆ)
    """
    speed = current_duration / desired_duration
    logging.debug(f"â†’ Applying speed change: {speed:.4f}Ã—")

    sound = AudioSegment.from_file(input_path)
    new_frame_rate = int(sound.frame_rate * speed)
    stretched = sound._spawn(sound.raw_data, overrides={"frame_rate": new_frame_rate})
    stretched = stretched.set_frame_rate(sound.frame_rate)
    ensure_folder(os.path.dirname(output_path))
    stretched.export(output_path, format="mp3", bitrate="192k")

    new_duration = len(stretched) / 1000.0
    logging.debug(f"â†’ New duration: {new_duration:.3f}s")
    return new_duration

def get_cps(cur, voice_id: str, lang: str, fallback: float = 6.1) -> float:
    """
    voice_lang_stats í…Œì´ë¸”ì—ì„œ (voice_id, lang) í–‰ì˜ char_per_secë¥¼ ë°˜í™˜.
    ì—†ìœ¼ë©´ fallback ê°’(ê¸°ë³¸ 6.1) ì‚¬ìš©.
    """
    cur.execute(
        "SELECT char_per_sec FROM voice_lang_stats WHERE voice_id=%s AND lang=%s;",
        (voice_id, lang[:2])
    )
    row = cur.fetchone()
    return row[0] if row else fallback

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  /generate-tts-from-stt
#     1) ì›ë³¸ STT â†’ ê¸¸ì´ì˜ì‹ ë²ˆì—­
#     2) TTS ìƒì„±Â·ê²€ì¦
#     3) translations  UPSERT
#     4) tts           INSERT ë˜ëŠ” UPDATE(file_pathë§Œ ìµœì‹ í™”)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/generate-tts-from-stt")
async def generate_tts_from_stt(data: dict):
    video_id = data.get("video_id")
    if not video_id:
        raise HTTPException(400, "video_id í•„ìš”")

    speaker_voice = {
        "A": "29vD33N1CtxCmqQRPOHJ",
        "B": "21m00Tcm4TlvDq8ikWAM",
        "C": "5Q0t7uMcjvnagumLfvZi",
    }
    MAX_RETRY, TOL = 20, 0.05
    tts_dir = os.path.join(AUDIO_FOLDER, f"{video_id}_tts")
    ensure_folder(tts_dir)

    with get_db_cursor() as cur:
        # â‘  ì˜ìƒì— ë”¸ë¦° STT ì¤„ ì¡°íšŒ
        cur.execute(
            """
            SELECT tr.transcript_id, tr.text, tr.start_time, tr.end_time,
                   tr.speaker,
                   LEFT(p.source_language,2), LEFT(p.target_language,2)
              FROM transcripts tr
              JOIN videos v ON v.video_id = tr.video_id
              JOIN projects p ON p.project_id = v.project_id
             WHERE tr.video_id = %s
             ORDER BY tr.start_time;
            """,
            (video_id,),
        )
        rows = cur.fetchall()

        for tid, src, st, et, spk, src_l, tgt_l in rows:
            dur = float(et) - float(st)
            voice = speaker_voice.get(spk)
            if dur <= 0 or not voice:
                continue

            # â‘¡ ê¸¸ì´-ë§ì¶¤ ë²ˆì—­
            text = translate_length_aware(
                src_text=src,
                src_lang=src_l,
                tgt_lang=tgt_l,
                dur_sec=dur,
                voice_id=voice,
                db_cursor=cur,
            )

            # â‘¢ TTS ìƒì„± & ê¸¸ì´ ê²€ìˆ˜
            for n in range(MAX_RETRY):
                tmp_path = os.path.join(tts_dir, f"tmp_{tid}_{n}.mp3")
                synth_to_file(voice, text, tmp_path)

                real = librosa.get_duration(path=tmp_path)
                if abs(real - dur) / dur <= TOL:
                    final_mp3, final_dur = tmp_path, real
                    break

                # ê¸¸ì´ ë¶ˆì¼ì¹˜ â†’ ê¸€ì ìˆ˜ ë¹„ë¡€ ì¬ì¡°ì •
                need_len = max(8, round(len(text) * dur / real))
                sys_msg = (
                    f"Rewrite to {need_len} "
                    f"{'syllables' if tgt_l=='ko' else 'chars'}. Keep names."
                )
                text = openai.ChatCompletion.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": sys_msg},
                        {"role": "user", "content": text},
                    ],
                    timeout=15,
                    request_timeout=15,
                ).choices[0].message.content.strip()
            else:
                # â”€â”€ fallback: SSML prosody rate ë³´ì •ìœ¼ë¡œ ìµœì¢… TTS ì¬ìƒì„± â”€â”€
                rate = dur / real
                ssml = f'<speak><prosody rate="{int(rate*100)}%">{text}</prosody></speak>'
                fallback_path = os.path.join(tts_dir, f"fallback_{tid}.mp3")
                synth_to_file(voice, ssml, fallback_path)
                final_dur = librosa.get_duration(path=fallback_path)
                final_mp3 = fallback_path

            # â‘£ translations UPSERT
            cur.execute(
                """
                INSERT INTO translations (transcript_id, language, text)
                VALUES (%s, %s, %s)
                ON CONFLICT (transcript_id, language)
                DO UPDATE SET text = EXCLUDED.text
                RETURNING translation_id;
                """,
                (tid, tgt_l, text),
            )
            translation_id = cur.fetchone()[0]

            # â‘¤ tts INSERT ë˜ëŠ” UPDATE(ê²½ë¡œÂ·ê¸¸ì´ë§Œ ìµœì‹ í™”)
            cur.execute(
                "SELECT tts_id FROM tts WHERE translation_id = %s;",
                (translation_id,),
            )
            row = cur.fetchone()
            if row:
                cur.execute(
                    """
                    UPDATE tts
                       SET file_path = %s,
                           voice     = %s,
                           duration  = %s
                     WHERE tts_id  = %s;
                    """,
                    (final_mp3, voice, final_dur, row[0]),
                )
            else:
                cur.execute(
                    """
                    INSERT INTO tts (translation_id, file_path, voice,
                                     start_time, duration)
                    VALUES (%s, %s, %s, %s, %s);
                    """,
                    (translation_id, final_mp3, voice, st, final_dur),
                )

    return {"message": "TTS ì™„ë£Œ"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  /edit-tts
#     1) ì¬ë²ˆì—­
#     2) ìƒˆ mp3 ìƒì„±Â·ê²€ì¦
#     3) translations UPSERT
#     4) tts row ë®ì–´ì“°ê¸° (file_path í¬í•¨)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/edit-tts")
async def edit_tts(
    tts_id: int   = Form(...),
    voice: str    = Form(...),
    text: str     = Form(...),
    update_src: bool = Form(True),
):
    MAX_RETRY, TOL = 5, 0.03

    with get_db_cursor() as cur:
        # ê¸°ì¡´ ì •ë³´
        cur.execute(
            """
            SELECT  tts.translation_id, ts.transcript_id,
                    tts.start_time, tts.duration, tts.file_path,
                    LEFT(p.source_language,2), LEFT(p.target_language,2)
              FROM  tts
              JOIN  translations t ON t.translation_id = tts.translation_id
              JOIN  transcripts  ts ON ts.transcript_id = t.transcript_id
              JOIN  videos       v  ON v.video_id       = ts.video_id
              JOIN  projects     p  ON p.project_id     = v.project_id
             WHERE  tts.tts_id = %s;
            """,
            (tts_id,),
        )
        (
            old_tran,
            trans_id,
            st,
            dur,
            old_path,
            src_l,
            tgt_l,
        ) = cur.fetchone()

        base_dir = os.path.dirname(old_path)
        ensure_folder(base_dir)

        # â‘  ì¬ë²ˆì—­
        new_text = translate_length_aware(
            src_text=text,
            src_lang=src_l,
            tgt_lang=tgt_l,
            dur_sec=dur,
            voice_id=voice,
            db_cursor=cur,
        )

        # â‘¡ mp3 ì¬ìƒì„±
        for n in range(MAX_RETRY):
            tmp_path = os.path.join(base_dir, f"tmp_{tts_id}_{n}.mp3")
            synth_to_file(voice, new_text, tmp_path)

            real = librosa.get_duration(path=tmp_path)
            if abs(real - dur) / dur <= TOL:
                final_mp3, final_dur = tmp_path, real
                break

            need_len = max(8, round(len(new_text) * dur / real))
            sys_msg  = (
                f"Rewrite to {need_len} "
                f"{'syllables' if tgt_l=='ko' else 'chars'}. Keep names."
            )
            new_text = openai.ChatCompletion.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": sys_msg},
                    {"role": "user",   "content": new_text},
                ],
            ).choices[0].message.content.strip()
        else:
            final_mp3, final_dur = tmp_path, real

        # â‘¢ translations UPSERT
        cur.execute(
            """
            INSERT INTO translations (transcript_id, language, text)
            VALUES (%s, %s, %s)
            ON CONFLICT (transcript_id, language)
            DO UPDATE SET text = EXCLUDED.text
            RETURNING translation_id;
            """,
            (trans_id, tgt_l, new_text),
        )
        new_tran_id = cur.fetchone()[0]

        # â‘£ tts ë®ì–´ì“°ê¸° (file_path í¬í•¨!)
        cur.execute(
            """
            UPDATE tts
               SET translation_id = %s,
                   file_path      = %s,
                   voice          = %s,
                   duration       = %s
             WHERE tts_id         = %s;
            """,
            (new_tran_id, final_mp3, voice, final_dur, tts_id),
        )

        # â‘¤ ì›ë³¸ STTë„ ë°”ê¿€ì§€ ì—¬ë¶€
        if update_src:
            cur.execute(
                "UPDATE transcripts SET text = %s WHERE transcript_id = %s;",
                (text, trans_id),
            )

    return {
        "tts_id": tts_id,
        "duration": final_dur,
        "file_path": final_mp3,
        "translation_id": new_tran_id,
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ê³µí†µ: ElevenLabs í˜¸ì¶œ ë˜í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def synth_to_file(voice_id: str, text: str, out_path: str):
    resp = requests.post(
        f"{ELEVENLABS_BASE_URL}/text-to-speech/{voice_id}"
        "?output_format=mp3_44100_128",
        headers={
            "xi-api-key": ELEVENLABS_API_KEY,
            "Content-Type": "application/json",
        },
        json={
            "text": text,
            "model_id": "eleven_multilingual_v2",
            "voice_settings": {"speed": 1.0},
        },
    )
    resp.raise_for_status()
    with open(out_path, "wb") as f:
        f.write(resp.content)


@app.post("/generate-tts")
async def generate_tts_custom(
    text: str = Form(...),           # TTSë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
    voice_id: str = Form(...),       # ì‚¬ìš©í•  Voice ID
    user_id: int = Form(...),        # ì‚¬ìš©ì ì‹ë³„ì
    tts_id: int = Form(None)         # ìˆ˜ì •í•  ê¸°ì¡´ TTS ID (ì—†ìœ¼ë©´ ìƒì„±)
):
    """
    user_id, text, voice_id, (tts_id)ë¥¼ Form ë°ì´í„°ë¡œ ë°›ì•„
    user_files/{user_id} í´ë”ì— TTS íŒŒì¼ ìƒì„± ë° DB ë°˜ì˜
    """
    try:
        # ì‚¬ìš©ìë³„ í´ë” ìƒì„±
        user_folder = os.path.join(USER_FILES_FOLDER, str(user_id))
        os.makedirs(user_folder, exist_ok=True)

        # DB ì»¤ë„¥ì…˜
        conn = get_connection()
        curs = conn.cursor()

        # ê¸°ì¡´ TTSê°€ ìˆìœ¼ë©´ translations ì—…ë°ì´íŠ¸, ìƒˆë¡œ ìƒì„±ì‹œ ì‚½ì…
        if tts_id:
            curs.execute("SELECT translation_id FROM tts WHERE tts_id = %s;", (tts_id,))
            row = curs.fetchone()
            if not row:
                raise HTTPException(status_code=404, detail="tts_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            translation_id = row[0]
            # ë²ˆì—­ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            curs.execute("UPDATE translations SET text = %s WHERE translation_id = %s;", (text, translation_id))
            filename = f"tts_{tts_id}.mp3"
        else:
            # ì‹ ê·œ ë²ˆì—­ ë ˆì½”ë“œ ì‚½ì…
            curs.execute(
                "INSERT INTO translations(text, language) VALUES(%s, %s) RETURNING translation_id;",
                (text, "en")  # ì–¸ì–´ì½”ë“œëŠ” í•„ìš”ì— ë”°ë¼ ìˆ˜ì •
            )
            translation_id = curs.fetchone()[0]
            filename = f"tts_{text}.mp3"

        # íŒŒì¼ ê²½ë¡œ
        output_path = os.path.join(user_folder, filename)

        # ElevenLabs TTS ìƒì„±
        url = f"{ELEVENLABS_BASE_URL}/text-to-speech/{voice_id}?output_format=mp3_44100_128"
        headers = {"xi-api-key": ELEVENLABS_API_KEY, "Content-Type": "application/json"}
        resp = requests.post(url, headers=headers, json={"text": text, "model_id": "eleven_multilingual_v2"})
        if resp.status_code != 200:
            raise HTTPException(status_code=500, detail=f"TTS ìƒì„± ì‹¤íŒ¨: {resp.text}")

        # íŒŒì¼ ì €ì¥ ë° ê¸¸ì´ ì¸¡ì •
        with open(output_path, 'wb') as f:
            f.write(resp.content)
        duration = librosa.get_duration(path=output_path)

        # DB tts í…Œì´ë¸” ë°˜ì˜
        if tts_id:
            curs.execute(
                "UPDATE tts SET voice = %s, duration = %s, file_path = %s WHERE tts_id = %s;",
                (voice_id, duration, output_path, tts_id)
            )
        else:
            curs.execute(
                "INSERT INTO tts(translation_id, file_path, voice, start_time, duration) VALUES(%s, %s, %s, %s, %s) RETURNING tts_id;",
                (translation_id, output_path, voice_id, 0.0, duration)
            )
            tts_id = curs.fetchone()[0]

        conn.commit()
        curs.close()
        conn.close()

        # URLì€ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë°˜í™˜í•˜ì§€ ì•ŠìŒ
        return JSONResponse({"message": "TTS ìƒì„± ì™„ë£Œ", "tts_id": tts_id})

    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"generate-tts error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/create-voice-model")
async def create_voice_model(
    background_tasks: BackgroundTasks,
    name: str = Form(...),
    description: str = Form(None),
    remove_background_noise: bool = Form(False),
    files: List[UploadFile] = File(...),
):
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ Spleeterë¡œ ë¶„ë¦¬ í›„ ìƒ˜í”Œì„ ìƒì„±,
    ElevenLabs APIë¡œ ë³´ì´ìŠ¤ ëª¨ë¸ì„ ë§Œë“  ë’¤ DBì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    all_sample_parts = []
    temp_paths = []
    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB

    # íŒŒì¼ ì²˜ë¦¬
    for file in files:
        file.file.seek(0, os.SEEK_END)
        size = file.file.tell()
        file.file.seek(0)
        if size > MAX_FILE_SIZE:
            raise HTTPException(status_code=400, detail=f"íŒŒì¼ {file.filename}ì˜ í¬ê¸°ê°€ 10MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")

        original_name = os.path.splitext(file.filename)[0]
        base_name = original_name[:-len("_audio")] if file.filename.endswith("_audio") else original_name
        original_path = os.path.join(AUDIO_FOLDER, f"{base_name}.mp3")
        logging.info(f"ğŸ“¥ íŒŒì¼ ì €ì¥ ì‹œì‘: {file.filename}")
        with open(original_path, "wb") as f:
            f.write(await file.read())
        temp_paths.append(original_path)

        if remove_background_noise:
            # TODO: ë°°ê²½ ì†ŒìŒ ì œê±° ì²˜ë¦¬ í˜¸ì¶œ
            pass

        try:
            separator = Separator("spleeter:2stems")
            separator.separate_to_file(original_path, AUDIO_FOLDER)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Spleeter ì‹¤í–‰ ì‹¤íŒ¨: {e}")

        vocal_path, _ = find_spleeter_vocals(AUDIO_FOLDER, base_name)
        fixed_vocal_path = os.path.join(AUDIO_FOLDER, f"{base_name}_vocals.wav")
        shutil.move(vocal_path, fixed_vocal_path)
        temp_paths.append(fixed_vocal_path)
        shutil.rmtree(os.path.join(AUDIO_FOLDER, base_name), ignore_errors=True)
        shutil.rmtree(os.path.join(AUDIO_FOLDER, f"{base_name}_audio"), ignore_errors=True)

        merge_dir = os.path.join(AUDIO_FOLDER, f"{base_name}_merged")
        os.makedirs(merge_dir, exist_ok=True)
        temp_paths.append(merge_dir)
        merged_sample = merge_nonsilent_audio_improved(
            fixed_vocal_path, merge_dir,
            output_filename="merged_sample.mp3",
            fade_duration=200
        )

        split_dir = os.path.join(AUDIO_FOLDER, f"{base_name}_split")
        os.makedirs(split_dir, exist_ok=True)
        temp_paths.append(split_dir)
        parts = split_merged_audio(
            merged_sample, split_dir,
            max_duration_sec=30, max_samples=25
        )
        all_sample_parts.extend(parts)

    if not all_sample_parts:
        raise HTTPException(status_code=500, detail="ìƒ˜í”Œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨")

    voice_response = create_voice_model_api(
        name=name,
        description=description,
        sample_file_paths=all_sample_parts
    )
    voice_id = voice_response.get("voice_id")
    if not voice_id:
        raise HTTPException(status_code=500, detail="ë³´ì´ìŠ¤ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: voice_idê°€ ë°˜í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    logging.info(f"âœ… ë³´ì´ìŠ¤ ëª¨ë¸ ìƒì„± ì™„ë£Œ: {voice_id}")

    # DB ì €ì¥
    with get_db_cursor() as curs:
        curs.execute(
            """
            INSERT INTO voice_models (voice_id, name, description)
            VALUES (%s, %s, %s)
            RETURNING id;
            """,
            (voice_id, name, description)
        )
        inserted_id = curs.fetchone()[0]
    logging.info(f"ğŸ“Œ DBì— voice_models ì €ì¥ ì™„ë£Œ (id: {inserted_id})")

    background_tasks.add_task(delete_temp_files, temp_paths)

    return JSONResponse(
        content={
            "message": "ë³´ì´ìŠ¤ ëª¨ë¸ ìƒì„± ì™„ë£Œ",
            "voice_id": voice_id,
            "name": name,
            "description": description,
            "db_id": inserted_id,
        },
        status_code=200
    )

    
@app.get("/voice-models")
async def list_voice_models():
    with get_db_cursor() as curs:
        curs.execute("""
            SELECT id, name, voice_id, description
            FROM voice_models
            ORDER BY id;
        """)
        rows = curs.fetchall()
    models = [
        {"db_id": row[0], "name": row[1], "voice_id": row[2], "description": row[3]}
        for row in rows
    ]
    return JSONResponse(content=models)