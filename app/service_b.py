import os
import time
import psycopg2
import logging
import requests
import librosa
import shutil
import subprocess
import json
import openai
from contextlib import contextmanager
from typing import Optional, List
from openai.error import RateLimitError, APIError, ServiceUnavailableError, Timeout
from openai import Audio  # Whisper í˜¸ì¶œìš©

import soundfile as sf  # íƒ€ì„ ìŠ¤íŠ¸ë ˆì¹­ í›„ ì˜¤ë””ì˜¤ ì €ì¥ìš©
import tensorflow as tf
from fastapi import FastAPI, UploadFile, File, HTTPException, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from pydub import AudioSegment
from pydub.silence import detect_nonsilent
from spleeter.separator import Separator

import regex as re     # pip install regex   â† ìœ ë‹ˆì½”ë“œ ê·¸ë©ì´ ë” í¸í•´ìš”
import unicodedata
from uuid import uuid4
from fastapi.staticfiles import StaticFiles

from PIL import Image, ImageDraw  # ì´ë¯¸ import ë˜ì–´ìˆìŒ
import librosa, numpy as np

# â”€â”€ NEW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_HIRA_RE  = re.compile(r'[\p{Hiragana}]')
_KATA_RE  = re.compile(r'[\p{Katakana}]')
_CHOON_RE = re.compile(r'ãƒ¼')           # ì¥ìŒë¶€í˜¸
_SMALL_RE = re.compile(r'[ã‚ƒã‚…ã‚‡ã‚¡ã‚£ã‚¥ã‚§ã‚©ãƒ£ãƒ¥ãƒ§ãƒ®ããƒã…ã‡ã‰ã‚]')  # ì¶•ì•½ìŒ
_EN_RE    = re.compile(r'[A-Za-z0-9]')  # ì˜ì–´Â·ìˆ«ì(0.5 ì ê°€ì¤‘)

# ----------------------------
# ê¸°ë³¸ ì„¤ì • ë° í™˜ê²½ ë³€ìˆ˜
# ----------------------------
logging.basicConfig(level=logging.DEBUG)

AUDIO_FOLDER = "extracted_audio"
os.makedirs(AUDIO_FOLDER, exist_ok=True)
CUSTOM_TTS_FOLDER = os.path.join(AUDIO_FOLDER, "custom_tts")
os.makedirs(CUSTOM_TTS_FOLDER, exist_ok=True)
VOICE_MODEL_FOLDER = "voice_models"
os.makedirs(VOICE_MODEL_FOLDER, exist_ok=True)
USER_FILES_FOLDER = "user_files"
os.makedirs(USER_FILES_FOLDER, exist_ok=True)
IMAGE_FOLDER = "images"
os.makedirs(IMAGE_FOLDER, exist_ok=True)
WAVEFORM_FOLDER = "waveforms"
os.makedirs(WAVEFORM_FOLDER, exist_ok=True)

# FastAPI ì•± ìƒì„±
app = FastAPI()

DB_NAME = "test"
DB_USER = "postgres"
DB_PASSWORD = "1234"
DB_HOST = "localhost"
DB_PORT = "5433"

ELEVENLABS_API_KEY = "eleven-key"
ELEVENLABS_BASE_URL = "https://api.elevenlabs.io/v1"

# OpenAI API ì„¤ì • (ë²ˆì—­ìš©)
OPENAI_API_KEY = "gpt-key"
openai.api_key = OPENAI_API_KEY


# â”€â”€ NEW: ì–¸ì–´ë³„ í‰ê·  ì½ê¸° ì†ë„ (ìŒì ˆ/ë¬¸ì per sec)
AVG_SYL_PER_SEC = {"ko": 6.2, "en": 6.19, "ja": 7.84, "zh": 5.18}
TOL_RATIO = 0.02
MIN_SENT_LEN = 4
SUPPORTED_LANGS = set(AVG_SYL_PER_SEC)  # {'ko','en','ja','zh'}
RETRY_STATUS = {429, 500, 502, 503, 504}
# â”€â”€ ì–¸ì–´ë³„ TTS ê¸¸ì´ í—ˆìš© ì˜¤ì°¨ (ì‹¤ì œ ê¸¸ì´ â†” ëª©í‘œ ê¸¸ì´ ë¹„ìœ¨) â”€â”€
LANG_TOL = {
    "ko": 0.1,   # ìŒì ˆÂ·í˜¸í¡ ê³ ë ¤
    "en": 0.05,
    "ja": 0.1,   # ëª¨ë¼ ë‹¨ìœ„ íŠ¹ì„±ìƒ 5% ì´ë‚´ ë§ì¶”ê¸° ë‚œì´ë„ â†‘
    "zh": 0.08,
}
def get_tol(lang_code: str) -> float:
    """ì–¸ì–´ ì½”ë“œ ì• ë‘ ê¸€ìë¡œ TOL ë°˜í™˜, ê¸°ë³¸ 5%"""
    return LANG_TOL.get(lang_code[:2], 0.05)


# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ----------------------------
# Pydantic ëª¨ë¸
# ----------------------------
class CustomTTSRequest(BaseModel):
    tts_id: Optional[int] = None
    voice_id: str
    text: str

# ----------------------------
# PostgreSQL ì—°ê²° í•¨ìˆ˜
# ----------------------------
def get_connection():
    conn = psycopg2.connect(
        dbname=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD,
        host=DB_HOST,
        port=DB_PORT
    )
    return conn

@contextmanager
def get_db_cursor():
    conn = get_connection()
    try:
        curs = conn.cursor()
        yield curs
        conn.commit()
    except Exception as e:
        conn.rollback()
        raise e
    finally:
        curs.close()
        conn.close()

# ----------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ----------------------------
def ensure_folder(path: str):
    os.makedirs(path, exist_ok=True)

def delete_temp_files(file_paths: List[str]):
    for fp in file_paths:
        try:
            if os.path.exists(fp):
                if os.path.isdir(fp):
                    shutil.rmtree(fp, ignore_errors=True)
                    logging.info(f"Deleted folder: {fp}")
                else:
                    os.remove(fp)
                    logging.info(f"Deleted file: {fp}")
        except Exception as e:
            logging.error(f"Failed to delete {fp}: {e}")


def gpt_call_with_retry(
    model,
    messages,
    max_retries=6,
    initial_delay=0.8,
    request_timeout=20,
    temperature=0.2,
    fallback_models=("gpt-4o-mini", "gpt-4-turbo"),
    **kwargs
):
    """
    OpenAI ChatCompletion ì§€ìˆ˜ ë°±ì˜¤í”„ + ì§€í„° ì¬ì‹œë„.
    ë§ˆì§€ë§‰ì—” í´ë°± ëª¨ë¸ë¡œë„ ì‹œë„.
    """
    import random, time
    delay = initial_delay
    last_err = None

    for attempt in range(1, max_retries + 1):
        try:
            return openai.ChatCompletion.create(
                model=model,
                messages=messages,
                temperature=temperature,
                request_timeout=request_timeout,
                **kwargs
            )
        except (RateLimitError, ServiceUnavailableError, Timeout, APIError) as e:
            last_err = e
            status = getattr(e, "http_status", None)
            # ì¬ì‹œë„ ëŒ€ìƒì´ ì•„ë‹ˆë©´ ì¦‰ì‹œ ì¤‘ë‹¨
            if status not in RETRY_STATUS and not isinstance(e, (Timeout,)):
                logging.error(f"[GPT] non-retryable: {e}")
                break
            if attempt == max_retries:
                break
            sleep_s = delay * (1 + random.random() * 0.5)  # ì§€í„°
            logging.warning(f"[GPT] retry {attempt}/{max_retries} in {sleep_s:.2f}s (err={e})")
            time.sleep(sleep_s)
            delay *= 2
        except Exception as e:
            last_err = e
            logging.exception(f"[GPT] unexpected: {e}")
            break

    # í´ë°± ëª¨ë¸ë“¤
    for fb in fallback_models:
        try:
            logging.warning(f"[GPT] fallback model: {fb}")
            return openai.ChatCompletion.create(
                model=fb,
                messages=messages,
                temperature=temperature,
                request_timeout=request_timeout,
                **kwargs
            )
        except Exception as e:
            last_err = e
            logging.warning(f"[GPT] fallback {fb} failed: {e}")

    raise last_err or RuntimeError("OpenAI call failed")

def _mora_count(text: str) -> int:
    """
    íˆë¼ê°€ë‚˜Â·ê°€íƒ€ì¹´ë‚˜Â·í•œì ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¼(mora)ë¥¼ ê·¼ì‚¬ ê³„ì‚°.
    - ì¥ìŒ(ãƒ¼)Â·ì¶•ì•½ìŒ(ã‚ƒ ë“±)ì€ 0.5 ë¡œ ê°€ì¤‘
    - ì˜ìˆ«ìëŠ” 0.5 ë¡œ ê°€ì¤‘ (ì˜ˆ: "ABC" â‰ˆ 1.5 mora)
    """
    cnt  = len(_HIRA_RE.findall(text)) + len(_KATA_RE.findall(text))
    cnt += len(re.findall(r'[\p{Han}]', text))          # í•œì(=1)
    cnt += 0.5 * (len(_CHOON_RE.findall(text)) +
                  len(_SMALL_RE.findall(text)) +
                  len(_EN_RE.findall(text)))
    return int(round(cnt))

def _weighted_len_zh(text: str) -> float:
    """ì¤‘êµ­ì–´: í•œì=1, ì˜ìˆ«ì=0.5, ê·¸ ì™¸=0.3 ë¡œ ê·¼ì‚¬"""
    han   = len(re.findall(r'[\p{Han}]', text))
    ennum = len(_EN_RE.findall(text))
    other = len(text) - han - ennum
    return han + 0.5*ennum + 0.3*other
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def count_units(txt: str, lang: str) -> int:
    """
    TTS ê¸¸ì´ ì˜ˆì¸¡ìš© ë‹¨ìœ„ ê³„ì‚°
    ko : â€œì™„ì„±í˜• í•œê¸€ ìŒì ˆâ€ë§Œ ì¹´ìš´íŠ¸
    ja : ëª¨ë¼(mora) ê·¼ì‚¬
    zh : ê°€ì¤‘ì¹˜ í•œììˆ˜
    ê¸°íƒ€(en ë“±) : ë¬¸ììˆ˜
    """
    if lang == "ko":
        # 1) NFD ì •ê·œí™”: ì™„ì„±í˜•â†’ì´ˆì¤‘ì¢…ì„± ìëª¨ë¡œ ë¶„í•´
        norm = unicodedata.normalize("NFD", txt)
        # 2) ì™„ì„±í˜• ìŒì ˆ ê°œìˆ˜
        syllables = sum(1 for c in norm if "\uAC00" <= c <= "\uD7A3")
        # 3) ìëª¨ ê°œìˆ˜ (Hangul Jamo & Compatibility Jamo)
        jamo = sum(1 for c in norm if (
            "\u1100" <= c <= "\u11FF" or   # Hangul Jamo
            "\u3130" <= c <= "\u318F"      # Compatibility Jamo
        ))
        cnt = syllables + 0.5 * jamo
        return int(round(cnt))

    if lang == "ja":
        return _mora_count(txt)

    if lang == "zh":
        return int(round(_weighted_len_zh(txt)))

    return len(txt)

def translate_length_aware(
    src_text: str,
    src_lang: str,
    tgt_lang: str,
    dur_sec: float,
    voice_id: str,
    db_cursor,
    retries: int = 6,
    tol_ratio: float = 0.03,   # ëª©í‘œ ìœ ë‹› ëŒ€ë¹„ Â±3%
    step_ratio: float = 0.05   # ëª©í‘œ ìœ ë‹›ì˜ 5%ë§Œí¼ goal ë³´ì •
) -> str:
    """
    ê¸¸ì´-ì˜ì‹ ë²ˆì—­(í…ìŠ¤íŠ¸ ì¬ì‘ì„± ì—†ì´): ê°€ì¥ ê·¼ì ‘í•œ ë²ˆì—­ë¬¸ì„ ë°˜í™˜.
    """
    tgt = tgt_lang[:2]
    cps = get_cps(db_cursor, voice_id, tgt)       # voice_lang_stats ì—†ìœ¼ë©´ fallback ì‚¬ìš©
    target = max(1, int(round(dur_sec * cps)))    # ëª©í‘œ ìœ ë‹› ìˆ˜
    tol    = max(2, int(round(target * tol_ratio)))
    lo, hi = target - tol, target + tol
    step   = max(1, int(round(target * step_ratio)))
    goal   = target

    best_text = None
    best_dev  = 10**9

    def _dev(txt: str) -> int:
        return abs(count_units(txt, tgt) - target)

    for _ in range(retries):
        sys_msg = (
            f"Translate from {src_lang[:2]} to {tgt}. "
            f"Make the output exactly {goal} units long. "
            "Keep proper nouns; do NOT summarize. "
            "Return ONLY the translation."
        )
        try:
            res = gpt_call_with_retry(
                model="gpt-4o",
                messages=[{"role": "system", "content": sys_msg},
                          {"role": "user",   "content": src_text}],
                request_timeout=15
            ).choices[0].message.content.strip()
        except Exception as e:
            logging.error(f"[translate_length_aware] retryable error: {e}")
            continue

        if not res:
            continue

        d = _dev(res)
        if d < best_dev:
            best_dev, best_text = d, res

        units = count_units(res, tgt)
        if lo <= units <= hi:
            return res  # í—ˆìš©ì˜¤ì°¨ ë‚´ë©´ ì¦‰ì‹œ ì¢…ë£Œ

        # ëª©í‘œ(goal) ë³´ì •ë§Œ ìˆ˜í–‰(í…ìŠ¤íŠ¸ëŠ” í™•ì •í•˜ì§€ ì•ŠìŒ)
        goal += step if units < lo else -step
        goal = max(lo, min(hi, goal))

    # ëª¨ë“  ì‹œë„ì—ì„œ í—ˆìš©ì˜¤ì°¨ ì‹¤íŒ¨ â†’ ê°€ì¥ ê·¼ì ‘í•œ í›„ë³´ ì‚¬ìš©(ì—†ìœ¼ë©´ ì›ë¬¸)
    return (best_text or src_text).strip()


# â€• Stretch (Â±3 % ì´ë‚´)
def stretch_audio(input_path: str, output_path: str, current_duration: float, desired_duration: float) -> float:
    speed = current_duration / desired_duration
    speed = max(0.90, min(1.03, speed))  # Â±3 %
    logging.debug(f"Speed change {speed:.3f}Ã—")

    sound = AudioSegment.from_file(input_path)
    new_fr = int(sound.frame_rate * speed)
    stretched = sound._spawn(sound.raw_data, overrides={"frame_rate": new_fr})
    stretched = stretched.set_frame_rate(sound.frame_rate)
    ensure_folder(os.path.dirname(output_path))
    stretched.export(output_path, format="mp3", bitrate="192k")
    return len(stretched) / 1000.0

def run_spleeter_subprocess(input_path: str, output_folder: str):
    command = [
        "python", "-m", "spleeter.separator",
        "separate_to_file", input_path, output_folder,
        "-p", "spleeter:2stems"
    ]
    logging.info("Spleeter subprocess command: " + " ".join(command))
    result = subprocess.run(command, capture_output=True, text=True)
    if result.returncode != 0:
        raise Exception("Spleeter subprocess failed: " + result.stderr)
    else:
        logging.info(result.stdout)

def find_spleeter_vocals(base_folder: str, base_name: str):
    vocals_candidates = []
    bgm_candidates = []
    primary_folder = os.path.join(base_folder, base_name)
    if os.path.exists(primary_folder):
        for root, dirs, files in os.walk(primary_folder):
            if "vocals.wav" in files:
                vocals_candidates.append(os.path.join(root, "vocals.wav"))
            if "accompaniment.wav" in files:
                bgm_candidates.append(os.path.join(root, "accompaniment.wav"))
    alternate_folder = os.path.join(base_folder, f"{base_name}_audio")
    if os.path.exists(alternate_folder):
        for root, dirs, files in os.walk(alternate_folder):
            if "vocals.wav" in files:
                vocals_candidates.append(os.path.join(root, "vocals.wav"))
            if "accompaniment.wav" in files:
                bgm_candidates.append(os.path.join(root, "accompaniment.wav"))
    if not vocals_candidates or not bgm_candidates:
        raise FileNotFoundError(
            f"âŒ '{base_folder}' ë‚´ì— '{base_name}' ë˜ëŠ” '{base_name}_audio' í´ë”ì—ì„œ í•„ìš”í•œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!"
        )
    # ì—¬ëŸ¬ ê°œ ìˆë”ë¼ë„ ì²« ë²ˆì§¸ í•­ëª©ë§Œ ì„ íƒí•´ì„œ ë°˜í™˜
    return vocals_candidates[0], bgm_candidates[0]


def split_audio(input_path: str, output_dir: str, max_size_mb: int = 10):
    ensure_folder(output_dir)
    try:
        audio = AudioSegment.from_file(input_path)
        threshold = audio.dBFS - 16
        nonsilent_ranges = detect_nonsilent(audio, min_silence_len=500, silence_thresh=threshold, seek_step=1)
        parts = []
        for idx, (start, end) in enumerate(nonsilent_ranges):
            if end - start < 1000:
                continue
            segment = audio[start:end]
            part_path = os.path.join(output_dir, f"part_{idx}.mp3")
            segment.export(part_path, format="mp3", bitrate="192k")
            parts.append(part_path)
        logging.info(f"ğŸ”¹ ë¶„í• ëœ íŒŒì¼ ê°œìˆ˜: {len(parts)}")
        max_samples = 25
        if len(parts) > max_samples:
            indices = [int(i * (len(parts) - 1) / (max_samples - 1)) for i in range(max_samples)]
            parts = [parts[i] for i in indices]
            logging.info(f"ğŸ”¹ ìƒ˜í”Œ ìˆ˜ê°€ ë§ì•„ ê· ì¼í•˜ê²Œ {max_samples}ê°œë¡œ ì¶•ì†Œí•¨")
        return parts
    except Exception as e:
        logging.error(f"âŒ ì˜¤ë””ì˜¤ ë¶„í•  ì‹¤íŒ¨: {str(e)}")
        return []

def merge_nonsilent_audio_improved(
    input_path: str,
    output_dir: str,
    min_silence_len: int = 500,
    silence_thresh: float = None,
    output_filename: str = "merged_sample.mp3",
    fade_duration: int = 200
):
    ensure_folder(output_dir)
    try:
        audio = AudioSegment.from_file(input_path)
        if silence_thresh is None:
            silence_thresh = audio.dBFS - 16
        nonsilent_ranges = detect_nonsilent(
            audio,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh,
            seek_step=1
        )
        merged_audio = AudioSegment.empty()
        for start, end in nonsilent_ranges:
            if end - start < 1000:
                continue
            segment = audio[start:end]
            segment = segment.fade_in(fade_duration).fade_out(fade_duration)
            merged_audio += segment
        output_path = os.path.join(output_dir, output_filename)
        merged_audio.export(output_path, format="mp3", bitrate="192k")
        logging.info(f"ğŸ”¹ ë³‘í•©ëœ íŒŒì¼ ìƒì„±: {output_path}")
        return output_path
    except Exception as e:
        logging.error(f"âŒ ë³‘í•© ì‹¤íŒ¨: {str(e)}")
        return None

def split_merged_audio(
    merged_path: str,
    output_dir: str,
    max_duration_sec: int = 30,
    max_samples: int = 25
):
    ensure_folder(output_dir)
    try:
        audio = AudioSegment.from_file(merged_path)
        duration_ms = len(audio)
        max_duration_ms = max_duration_sec * 1000
        parts = []
        if duration_ms <= max_duration_ms:
            parts.append(merged_path)
        else:
            num_parts = (duration_ms + max_duration_ms - 1) // max_duration_ms
            for i in range(num_parts):
                start = i * max_duration_ms
                end = min((i + 1) * max_duration_ms, duration_ms)
                segment = audio[start:end]
                part_path = os.path.join(output_dir, f"merged_part_{i}.mp3")
                segment.export(part_path, format="mp3", bitrate="192k")
                parts.append(part_path)
        if len(parts) > max_samples:
            indices = [
                int(i * (len(parts) - 1) / (max_samples - 1))
                for i in range(max_samples)
            ]
            parts = [parts[i] for i in indices]
            logging.info(f"ğŸ”¹ ë³‘í•© ìƒ˜í”Œ ìˆ˜ê°€ ë§ì•„ ê· ì¼í•˜ê²Œ {max_samples}ê°œë¡œ ì¶•ì†Œí•¨")
        return parts
    except Exception as e:
        logging.error(f"âŒ ë³‘í•© í›„ ë¶„í•  ì‹¤íŒ¨: {str(e)}")
        return []

def create_voice_model_api(name: str, description: str, sample_file_paths: List[str]):
    url = f"{ELEVENLABS_BASE_URL}/voices/add"
    headers = {"xi-api-key": ELEVENLABS_API_KEY}
    data = {"name": name, "description": description}
    files = []
    for path in sample_file_paths:
        try:
            f = open(path, "rb")
        except Exception as e:
            logging.error(f"íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨ ({path}): {str(e)}")
            continue
        files.append(("files", (os.path.basename(path), f, "audio/mpeg")))
    try:
        response = requests.post(url, headers=headers, data=data, files=files)
        response.raise_for_status()
        return response.json()
    finally:
        for _, file_tuple in files:
            file_tuple[1].close()

def adjust_tts_duration(file_path: str, desired_duration: float, max_change: float = 0.25) -> float:
    """
    ìƒì„±ëœ TTS íŒŒì¼ì„ ëª©í‘œ ê¸¸ì´ì— ë§ê²Œ ì‹œê°„ ìŠ¤íŠ¸ë ˆì¹­(í”¼ì¹˜ ë³´ì¡´).
    max_change=0.25 â†’ 0.8~1.25ë°° ë²”ìœ„ë¡œ ì œí•œ.
    """
    y, sr = librosa.load(file_path, sr=None)
    current_duration = librosa.get_duration(y=y, sr=sr)
    if desired_duration <= 0 or current_duration <= 0:
        return current_duration

    rate = current_duration / desired_duration           # >1ì´ë©´ ë” ë¹ ë¥´ê²Œ(ì§§ì•„ì§)
    lo, hi = (1.0 / (1.0 + max_change)), (1.0 + max_change)
    rate = min(max(rate, lo), hi)

    logging.info(
        f"[adjust_tts_duration] cur={current_duration:.3f}s -> tgt={desired_duration:.3f}s, rate={rate:.3f}"
    )

    y_stretched = librosa.effects.time_stretch(y, rate=rate)
    sf.write(file_path, y_stretched, sr)
    new_duration = librosa.get_duration(y=y_stretched, sr=sr)
    logging.info(f"[adjust_tts_duration] new={new_duration:.3f}s")
    return new_duration

# ----------------------------
# FastAPI ì—”ë“œí¬ì¸íŠ¸
# ----------------------------
app.mount("/uploaded_videos", StaticFiles(directory="uploaded_videos"), name="videos")
app.mount("/extracted_audio", StaticFiles(directory="extracted_audio"), name="audio")
app.mount("/images", StaticFiles(directory=IMAGE_FOLDER), name="images")
app.mount("/waveforms", StaticFiles(directory=WAVEFORM_FOLDER), name="waveforms")


@app.get("/")
def read_root():
    return {"message": "Hello from Service B (TTS Creation)!"}

@app.post("/separate-audio")
async def separate_audio(file: UploadFile = File(...)):
    try:
        original_name = os.path.splitext(file.filename)[0]
        base_name = (
            original_name[:-len("_audio")]
            if file.filename.endswith("_audio")
            else original_name
        )
        input_path = os.path.join(AUDIO_FOLDER, f"{base_name}.mp3")
        with open(input_path, "wb") as f:
            f.write(await file.read())
        logging.info(f"ì…ë ¥ ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {input_path}")

        from spleeter.separator import Separator
        separator = Separator("spleeter:2stems")
        separator.separate_to_file(input_path, AUDIO_FOLDER)
        logging.info("Spleeter ë¶„ë¦¬ ì‹¤í–‰ ì™„ë£Œ")

        vocals_path, bgm_path = find_spleeter_vocals(AUDIO_FOLDER, base_name)
        logging.info(f"ë¶„ë¦¬ëœ íŒŒì¼ ì°¾ìŒ: vocals={vocals_path}, bgm={bgm_path}")

        return JSONResponse(
            content={
                "message": "Spleeter ë¶„ë¦¬ ì™„ë£Œ",
                "vocals_path": vocals_path,
                "bgm_path": bgm_path
            },
            status_code=200
        )
    except Exception as e:
        logging.error(f"Spleeter ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"Spleeter ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
        )

def get_cps(cur, voice_id: str, lang: str, fallback: float = 6.1) -> float:
    """
    voice_lang_stats í…Œì´ë¸”ì—ì„œ (voice_id, lang) í–‰ì˜ char_per_secë¥¼ ë°˜í™˜.
    ì—†ìœ¼ë©´ fallback ê°’(ê¸°ë³¸ 6.1) ì‚¬ìš©.
    """
    cur.execute(
        "SELECT char_per_sec FROM voice_lang_stats WHERE voice_id=%s AND lang=%s;",
        (voice_id, lang[:2])
    )
    row = cur.fetchone()
    return row[0] if row else fallback

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ê³µí†µ: ElevenLabs í˜¸ì¶œ ë˜í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# --- helper: ì†ë„ ì¸ì ì§€ì› ë²„ì „ ---
def synth_to_file(
    voice_id: str,
    text: str,
    out_path: str,
    speed: float | None = None,
    model_id: str = "eleven_multilingual_v2",
):
    payload = {"text": text, "model_id": model_id}
    if speed is not None:
        sp = max(0.7, min(1.2, float(speed)))  # ê¶Œì¥ ë²”ìœ„
        payload["voice_settings"] = {"speed": sp}

    resp = requests.post(
        f"{ELEVENLABS_BASE_URL}/text-to-speech/{voice_id}?output_format=mp3_44100_128",
        headers={"xi-api-key": ELEVENLABS_API_KEY, "Content-Type": "application/json"},
        json=payload,
        timeout=30,
    )
    resp.raise_for_status()
    with open(out_path, "wb") as f:
        f.write(resp.content)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  /generate-tts-from-stt
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  /generate-tts-from-stt
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/generate-tts-from-stt")
async def generate_tts_from_stt(data: dict):
    video_id = data.get("video_id")
    if not video_id:
        raise HTTPException(400, "video_id í•„ìš”")

    speaker_voice = {
        "A": "29vD33N1CtxCmqQRPOHJ",
        "B": "21m00Tcm4TlvDq8ikWAM",
        "C": "5Q0t7uMcjvnagumLfvZi",
    }
    MAX_REWRITE_RETRY = 5
    tts_dir = os.path.join(AUDIO_FOLDER, f"{video_id}_tts")
    ensure_folder(tts_dir)

    failed: list[dict] = []
    generated_cnt = 0

    with get_db_cursor() as cur:
        cur.execute(
            """
            SELECT tr.transcript_id, tr.text, tr.start_time, tr.end_time,
                   tr.speaker,
                   LEFT(p.source_language,2) AS src_l,
                   LEFT(p.target_language,2) AS tgt_l
              FROM transcripts tr
              JOIN videos   v ON v.video_id = tr.video_id
              JOIN projects p ON p.project_id = v.project_id
             WHERE tr.video_id = %s
             ORDER BY tr.start_time ASC;
            """,
            (video_id,),
        )
        rows = cur.fetchall()

        for tid, src, st, et, spk, src_l, tgt_l in rows:
            try:
                dur   = float(et) - float(st)
                voice = speaker_voice.get(spk)
                if dur <= 0 or not voice:
                    continue

                TOL = get_tol(tgt_l)

                # â‘  ê¸¸ì´-ì˜ì‹ ë²ˆì—­(ì‹œë“œ)
                text = translate_length_aware(
                    src_text=src,
                    src_lang=src_l,
                    tgt_lang=tgt_l,
                    dur_sec=dur,
                    voice_id=voice,
                    db_cursor=cur,
                )

                # â‘¡ í•©ì„±/ê²€ì¦ ë£¨í”„ + "ê°€ì¥ ê·¼ì ‘" í›„ë³´ ê¸°ì–µ
                best_delta = float("inf")
                best_mp3   = None
                best_dur   = None
                best_text  = None

                chosen_path = None
                chosen_dur  = None
                chosen_text = None

                for n in range(MAX_REWRITE_RETRY):
                    tmp_path = os.path.join(tts_dir, f"tmp_{tid}_{n}.mp3")
                    synth_to_file(voice, text, tmp_path)

                    real = librosa.get_duration(path=tmp_path) or 0.0
                    delta = abs(real - dur)

                    if delta < best_delta:
                        best_delta, best_mp3, best_dur, best_text = delta, tmp_path, real, text

                    if dur > 0 and abs(real - dur) / dur <= TOL:
                        chosen_path, chosen_dur, chosen_text = tmp_path, real, text
                        break

                    # ë‹¤ìŒ ì‹œë„ë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ê¸¸ì´ ì¬ì‘ì„±
                    safe_real = real if real > 0 else 1e-6
                    need_len  = max(8, round(len(text) * dur / safe_real))
                    unit_nm   = (
                        'syllables' if tgt_l == 'ko'
                        else 'mora' if tgt_l == 'ja'
                        else 'han characters' if tgt_l == 'zh'
                        else 'chars'
                    )
                    sys_msg = f"Rewrite to {need_len} {unit_nm}. Keep proper nouns; do NOT summarize."
                    try:
                        text = gpt_call_with_retry(
                            model="gpt-4o",
                            messages=[
                                {"role": "system", "content": sys_msg},
                                {"role": "user",   "content": text},
                            ],
                            request_timeout=15,
                        ).choices[0].message.content.strip()
                    except Exception as e:
                        logging.warning(f"[rewrite] GPT ì‹¤íŒ¨(ê³„ì† ì§„í–‰): {e}")

                # â‘¢ 8íšŒ ëª¨ë‘ ì‹¤íŒ¨ â†’ 'ê°€ì¥ ê·¼ì ‘' í…ìŠ¤íŠ¸ë¡œ speed/SSML/íƒ€ì„ìŠ¤íŠ¸ë ˆì¹˜ ìˆœ í´ë°±
                if chosen_path is None:
                    if not best_mp3:
                        raise RuntimeError("í•©ì„±ì— ì‹¤íŒ¨í•˜ì—¬ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

                    chosen_text = best_text
                    chosen_dur  = best_dur
                    chosen_path = best_mp3

                    try:
                        if best_dur and dur > 0:
                            needed = dur / best_dur  # í•„ìš”í•œ ì†ë„ ë°°ìœ¨
                            if 0.7 <= needed <= 1.2:
                                speed_path = os.path.join(tts_dir, f"best_{tid}_spd.mp3")
                                synth_to_file(voice, best_text, speed_path, speed=needed)
                                real_spd = librosa.get_duration(path=speed_path) or best_dur
                                chosen_path, chosen_dur = speed_path, real_spd
                            else:
                                rate_pct = int((dur / (best_dur or dur or 1.0)) * 100)
                                ssml = f'<speak><prosody rate="{rate_pct}%">{best_text}</prosody></speak>'
                                ssml_path = os.path.join(tts_dir, f"best_{tid}_ssml.mp3")
                                synth_to_file(voice, ssml, ssml_path)
                                chosen_path = ssml_path
                                chosen_dur  = librosa.get_duration(path=ssml_path) or best_dur
                    except Exception as e:
                        logging.warning(f"[speed/ssml-fallback] ì‹¤íŒ¨: {e}")
                        try:
                            new_d = adjust_tts_duration(chosen_path, dur, max_change=0.25)
                            chosen_dur = new_d
                        except Exception as e2:
                            logging.warning(f"[adjust-fallback] ì‹¤íŒ¨(ê·¸ëƒ¥ ì§„í–‰): {e2}")

                final_mp3, final_dur, final_text = chosen_path, chosen_dur, chosen_text

                # â‘£ translations UPSERT (ì €ì¥ í…ìŠ¤íŠ¸ = chosen/best í…ìŠ¤íŠ¸)
                cur.execute(
                    """
                    INSERT INTO translations (transcript_id, language, text)
                    VALUES (%s, %s, %s)
                    ON CONFLICT (transcript_id, language)
                    DO UPDATE SET text = EXCLUDED.text
                    RETURNING translation_id;
                    """,
                    (tid, tgt_l, final_text),
                )
                translation_id = cur.fetchone()[0]

                # â‘¤ íŒŒí˜• ìƒì„± + tts INSERT/UPDATE (STT ì‹œê°„ê°’ ë³´ì¡´)
                wave_name = f"tts_{tid}.png"
                wave_path = os.path.join(WAVEFORM_FOLDER, wave_name)
                width_px  = int(max(1, round(float(final_dur) * 100)))
                generate_waveform_png(final_mp3, wave_path, width_px=width_px, height_px=100)
                wave_url = f"/waveforms/{wave_name}"

                cur.execute("SELECT tts_id FROM tts WHERE translation_id = %s;", (translation_id,))
                row = cur.fetchone()
                if row:
                    cur.execute(
                        """
                        UPDATE tts
                           SET file_path=%s, voice=%s, duration=%s, waveform_url=%s
                         WHERE tts_id=%s;
                        """,
                        (final_mp3, voice, final_dur, wave_url, row[0]),
                    )
                else:
                    cur.execute(
                        """
                        INSERT INTO tts (translation_id, file_path, voice, start_time, duration, waveform_url)
                        VALUES (%s, %s, %s, %s, %s, %s);
                        """,
                        (translation_id, final_mp3, voice, st, final_dur, wave_url),
                    )

                generated_cnt += 1

            except Exception as e:
                logging.error(f"[generate_tts_from_stt] segment {tid} ì‹¤íŒ¨: {e}")
                failed.append({"transcript_id": tid, "error": str(e)})
                continue

    if failed:
        return JSONResponse(
            status_code=207,
            content={"detail": "partial", "generated": generated_cnt, "failed": failed}
        )
    return {"message": "TTS ì™„ë£Œ", "generated": generated_cnt}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  /edit-tts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/edit-tts")
async def edit_tts(
    tts_id: int = Form(...),
    voice: str = Form(...),
    text: str = Form(...),
    update_src: bool = Form(True),
):
    MAX_RETRY = 5

    with get_db_cursor() as cur:
        cur.execute(
            """
            SELECT  tts.translation_id,
                    ts.transcript_id,
                    tts.start_time,
                    tts.duration,
                    tts.file_path,
                    LEFT(p.source_language,2) AS src_l,
                    LEFT(p.target_language,2) AS tgt_l
              FROM tts
              JOIN translations tr ON tr.translation_id = tts.translation_id
              JOIN transcripts ts     ON ts.transcript_id     = tr.transcript_id
              JOIN videos v           ON v.video_id            = ts.video_id
              JOIN projects p         ON p.project_id          = v.project_id
             WHERE tts.tts_id = %s;
            """,
            (tts_id,)
        )
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="TTS ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

        old_tran_id, transcript_id, start_time, target_dur, old_path, src_l, tgt_l = row
        base_dir = os.path.dirname(old_path)
        ensure_folder(base_dir)

        TOL = get_tol(tgt_l)

        # ê¸¸ì´-ì˜ì‹ ë²ˆì—­(ì‹œë“œ)
        new_text = translate_length_aware(
            src_text=text,
            src_lang=src_l,
            tgt_lang=tgt_l,
            dur_sec=target_dur,
            voice_id=voice,
            db_cursor=cur,
        )

        best_delta = float("inf")
        best_mp3   = None
        best_dur   = None
        best_text  = None

        final_path = None
        final_dur  = None
        final_text = None

        for n in range(MAX_RETRY):
            tmp_file = os.path.join(base_dir, f"edit_{tts_id}_{n}.mp3")
            synth_to_file(voice, new_text, tmp_file)

            real_dur = librosa.get_duration(path=tmp_file) or 0.0
            delta = abs(real_dur - target_dur)

            if delta < best_delta:
                best_delta, best_mp3, best_dur, best_text = delta, tmp_file, real_dur, new_text

            if target_dur > 0 and abs(real_dur - target_dur) / target_dur <= TOL:
                final_path, final_dur, final_text = tmp_file, real_dur, new_text
                break

            # ì¬ì‘ì„±
            need_len = max(8, round(len(new_text) * target_dur / max(real_dur, 1e-6)))
            unit_nm = (
                'syllables' if tgt_l == 'ko'
                else 'mora' if tgt_l == 'ja'
                else 'han characters' if tgt_l == 'zh'
                else 'chars'
            )
            sys_msg = f"Rewrite to {need_len} {unit_nm}. Keep names."
            try:
                new_text = gpt_call_with_retry(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": sys_msg},
                        {"role": "user",   "content": new_text},
                    ],
                    request_timeout=15,
                ).choices[0].message.content.strip()
            except Exception as e:
                logging.warning(f"[edit-tts/rewrite] GPT ì‹¤íŒ¨(ê³„ì†): {e}")

        # ìµœëŒ€ ì‹œë„ ì´ˆê³¼ â†’ 'ê°€ì¥ ê·¼ì ‘' í…ìŠ¤íŠ¸ë¡œ speed/SSML/íƒ€ì„ìŠ¤íŠ¸ë ˆì¹˜ ìˆœ í´ë°±
        if final_path is None:
            if not best_mp3:
                raise RuntimeError("í•©ì„±ì— ì‹¤íŒ¨í•˜ì—¬ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

            final_text = best_text
            final_dur  = best_dur
            final_path = best_mp3

            try:
                if best_dur and target_dur > 0:
                    needed = target_dur / best_dur
                    if 0.7 <= needed <= 1.2:
                        speed_file = os.path.join(base_dir, f"edit_{tts_id}_best_spd.mp3")
                        synth_to_file(voice, best_text, speed_file, speed=needed)
                        real_spd = librosa.get_duration(path=speed_file) or best_dur
                        final_path, final_dur = speed_file, real_spd
                    else:
                        rate_pct = int((target_dur / (best_dur or target_dur or 1.0)) * 100)
                        ssml = f'<speak><prosody rate="{rate_pct}%">{best_text}</prosody></speak>'
                        ssml_file = os.path.join(base_dir, f"edit_{tts_id}_best_ssml.mp3")
                        synth_to_file(voice, ssml, ssml_file)
                        final_path = ssml_file
                        final_dur  = librosa.get_duration(path=ssml_file) or best_dur
            except Exception as e:
                logging.warning(f"[edit/speed-ssml-fallback] ì‹¤íŒ¨: {e}")
                try:
                    new_d = adjust_tts_duration(final_path, target_dur, max_change=0.25)
                    final_dur = new_d
                except Exception as e2:
                    logging.warning(f"[edit/adjust-fallback] ì‹¤íŒ¨(ê·¸ëƒ¥ ì§„í–‰): {e2}")

        # translations UPSERT (ì €ì¥ í…ìŠ¤íŠ¸ = ìµœì¢… ì„ íƒ í…ìŠ¤íŠ¸)
        cur.execute(
            """
            INSERT INTO translations (transcript_id, language, text)
            VALUES (%s, %s, %s)
            ON CONFLICT (transcript_id, language)
            DO UPDATE SET text = EXCLUDED.text
            RETURNING translation_id;
            """,
            (transcript_id, tgt_l, final_text),
        )
        new_translation_id = cur.fetchone()[0]

        # íŒŒí˜• ê°±ì‹ 
        wave_name = f"tts_{tts_id}.png"
        wave_path = os.path.join(WAVEFORM_FOLDER, wave_name)
        width_px  = int(max(1, round(float(final_dur) * 100)))
        generate_waveform_png(final_path, wave_path, width_px=width_px, height_px=100)
        wave_url = f"/waveforms/{wave_name}"

        # tts ì—…ë°ì´íŠ¸ (STT ì‹œê°„ê°’ ë¶ˆë³€)
        cur.execute(
            """
            UPDATE tts
               SET translation_id = %s,
                   file_path      = %s,
                   voice          = %s,
                   duration       = %s,
                   waveform_url   = %s
             WHERE tts_id        = %s;
            """,
            (new_translation_id, final_path, voice, final_dur, wave_url, tts_id),
        )

        if update_src:
            cur.execute(
                "UPDATE transcripts SET text = %s WHERE transcript_id = %s;",
                (text, transcript_id),
            )

    return {
        "id": tts_id,
        "duration": final_dur,
        "url": final_path,
        "translation_id": new_translation_id,
        "translateText": final_text,
        "originalText": text,
        "waveform_url": wave_url,
        "message": "TTS ìˆ˜ì • ì™„ë£Œ"
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  /generate-tts  (custom TTS ìƒì„±/ìˆ˜ì •)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/generate-tts")
async def generate_tts_custom(
    text: str = Form(...),           # TTSë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
    voice_id: str = Form(...),       # ì‚¬ìš©í•  Voice ID
    user_id: int = Form(...),        # ì‚¬ìš©ì ì‹ë³„ì
    tts_id: int = Form(None)         # ìˆ˜ì •í•  ê¸°ì¡´ TTS ID (ì—†ìœ¼ë©´ ìƒì„±)
):
    """
    user_id, text, voice_id, (tts_id)ë¥¼ Form ë°ì´í„°ë¡œ ë°›ì•„
    user_files/{user_id} í´ë”ì— TTS íŒŒì¼ ìƒì„± ë° DB ë°˜ì˜ + íŒŒí˜• ìƒì„±(waveform_url ì €ì¥)
    """
    try:
        # ì‚¬ìš©ìë³„ í´ë” ìƒì„±
        user_folder = os.path.join(USER_FILES_FOLDER, str(user_id))
        os.makedirs(user_folder, exist_ok=True)

        # DB ì»¤ë„¥ì…˜
        conn = get_connection()
        curs = conn.cursor()

        # ê¸°ì¡´ TTSê°€ ìˆìœ¼ë©´ translations ì—…ë°ì´íŠ¸, ìƒˆë¡œ ìƒì„±ì‹œ ì‚½ì…
        if tts_id:
            curs.execute("SELECT translation_id FROM tts WHERE tts_id = %s;", (tts_id,))
            row = curs.fetchone()
            if not row:
                raise HTTPException(status_code=404, detail="tts_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            translation_id = row[0]
            # ë²ˆì—­ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            curs.execute("UPDATE translations SET text = %s WHERE translation_id = %s;", (text, translation_id))
            filename = f"tts_{tts_id}.mp3"
        else:
            # ì‹ ê·œ ë²ˆì—­ ë ˆì½”ë“œ ì‚½ì…
            curs.execute(
                "INSERT INTO translations(text, language) VALUES(%s, %s) RETURNING translation_id;",
                (text, "en")  # ì–¸ì–´ì½”ë“œëŠ” í•„ìš”ì— ë”°ë¼ ìˆ˜ì •
            )
            translation_id = curs.fetchone()[0]
            # ìš°ì„  ì„ì‹œ ì´ë¦„ìœ¼ë¡œ ìƒì„± (tts_idë¥¼ ì•Œê¸° ì „)
            filename = f"tts_tmp_{uuid4().hex}.mp3"

        # íŒŒì¼ ê²½ë¡œ
        output_path = os.path.join(user_folder, filename)

        # ElevenLabs TTS ìƒì„±
        url = f"{ELEVENLABS_BASE_URL}/text-to-speech/{voice_id}?output_format=mp3_44100_128"
        headers = {"xi-api-key": ELEVENLABS_API_KEY, "Content-Type": "application/json"}
        resp = requests.post(url, headers=headers, json={"text": text, "model_id": "eleven_multilingual_v2"})
        if resp.status_code != 200:
            raise HTTPException(status_code=500, detail=f"TTS ìƒì„± ì‹¤íŒ¨: {resp.text}")

        # íŒŒì¼ ì €ì¥ ë° ê¸¸ì´ ì¸¡ì •
        with open(output_path, 'wb') as f:
            f.write(resp.content)
        duration = librosa.get_duration(path=output_path)

        # DB tts í…Œì´ë¸” ë°˜ì˜ + íŒŒí˜• ìƒì„±
        if tts_id:
            # íŒŒí˜• ë¨¼ì € ìƒì„±
            wave_name = f"tts_{tts_id}.png"
            wave_path = os.path.join(WAVEFORM_FOLDER, wave_name)
            width_px  = int(max(1, round(float(duration) * 100)))
            generate_waveform_png(output_path, wave_path, width_px=width_px, height_px=100)
            wave_url = f"/waveforms/{wave_name}"

            # tts ì—…ë°ì´íŠ¸
            curs.execute(
                "UPDATE tts SET voice = %s, duration = %s, file_path = %s, waveform_url = %s WHERE tts_id = %s;",
                (voice_id, duration, output_path, wave_url, tts_id)
            )
        else:
            # tts ì‹ ê·œ ì‚½ì…í•˜ì—¬ tts_id í™•ë³´
            curs.execute(
                """
                INSERT INTO tts(translation_id, file_path, voice, start_time, duration)
                VALUES(%s, %s, %s, %s, %s) RETURNING tts_id;
                """,
                (translation_id, output_path, voice_id, 0.0, duration)
            )
            tts_id = curs.fetchone()[0]

            # íŒŒì¼ëª…ì„ tts_id ê¸°ì¤€ìœ¼ë¡œ ì •ì • (ì„ íƒ ì‚¬í•­)
            new_filename = f"tts_{tts_id}.mp3"
            new_output_path = os.path.join(user_folder, new_filename)
            if new_output_path != output_path:
                try:
                    os.replace(output_path, new_output_path)
                    output_path = new_output_path
                    curs.execute(
                        "UPDATE tts SET file_path = %s WHERE tts_id = %s;",
                        (output_path, tts_id)
                    )
                except Exception:
                    pass  # íŒŒì¼ëª… ë³€ê²½ ì‹¤íŒ¨í•´ë„ ì¹˜ëª…ì ì´ì§„ ì•Šìœ¼ë‹ˆ ë¬´ì‹œ

            # íŒŒí˜• ìƒì„± í›„ URL ì €ì¥
            wave_name = f"tts_{tts_id}.png"
            wave_path = os.path.join(WAVEFORM_FOLDER, wave_name)
            width_px  = int(max(1, round(float(duration) * 100)))
            generate_waveform_png(output_path, wave_path, width_px=width_px, height_px=100)
            wave_url = f"/waveforms/{wave_name}"
            curs.execute(
                "UPDATE tts SET waveform_url=%s WHERE tts_id=%s;",
                (wave_url, tts_id)
            )

        conn.commit()
        curs.close()
        conn.close()

        return JSONResponse({"message": "TTS ìƒì„± ì™„ë£Œ", "tts_id": tts_id, "waveform_url": wave_url})

    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"generate-tts error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/create-voice-model")
async def create_voice_model(
    background_tasks: BackgroundTasks,
    name: str = Form(...),
    description: str = Form(None),
    remove_background_noise: bool = Form(False),
    files: List[UploadFile] = File(...),
    image: UploadFile = File(None),           # â† NEW: ì´ë¯¸ì§€ ìˆ˜ì‹  í•„ë“œ
):
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„â€¦
    ElevenLabs APIë¡œ ë³´ì´ìŠ¤ ëª¨ë¸ì„ ë§Œë“  ë’¤ DBì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    all_sample_parts = []
    temp_paths = []
    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB

    # â”€â”€ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ â”€â”€
    for file in files:
        file.file.seek(0, os.SEEK_END)
        size = file.file.tell()
        file.file.seek(0)
        if size > MAX_FILE_SIZE:
            raise HTTPException(status_code=400, detail=f"íŒŒì¼ {file.filename}ì´ 10MB ì´ˆê³¼")

        original_name = os.path.splitext(file.filename)[0]
        base_name = (
            original_name[:-len("_audio")]
            if file.filename.endswith("_audio")
            else original_name
        )
        original_path = os.path.join(AUDIO_FOLDER, f"{base_name}.mp3")
        logging.info(f"ì €ì¥: {original_path}")
        with open(original_path, "wb") as f:
            f.write(await file.read())
        temp_paths.append(original_path)

        if remove_background_noise:
            # TODO: ë°°ê²½ ì†ŒìŒ ì œê±°
            pass

        # Spleeter ë¶„ë¦¬
        try:
            separator = Separator("spleeter:2stems")
            separator.separate_to_file(original_path, AUDIO_FOLDER)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Spleeter ì‹¤íŒ¨: {e}")

        vocal_path, _ = find_spleeter_vocals(AUDIO_FOLDER, base_name)
        fixed_vocal_path = os.path.join(AUDIO_FOLDER, f"{base_name}_vocals.wav")
        shutil.move(vocal_path, fixed_vocal_path)
        temp_paths.append(fixed_vocal_path)
        shutil.rmtree(os.path.join(AUDIO_FOLDER, base_name), ignore_errors=True)
        shutil.rmtree(os.path.join(AUDIO_FOLDER, f"{base_name}_audio"), ignore_errors=True)

        # ìƒ˜í”Œ ë³‘í•©
        merge_dir = os.path.join(AUDIO_FOLDER, f"{base_name}_merged")
        os.makedirs(merge_dir, exist_ok=True)
        temp_paths.append(merge_dir)
        merged_sample = merge_nonsilent_audio_improved(
            fixed_vocal_path, merge_dir,
            output_filename="merged_sample.mp3",
            fade_duration=200
        )

        # ìƒ˜í”Œ ë¶„í• 
        split_dir = os.path.join(AUDIO_FOLDER, f"{base_name}_split")
        os.makedirs(split_dir, exist_ok=True)
        temp_paths.append(split_dir)
        parts = split_merged_audio(
            merged_sample, split_dir,
            max_duration_sec=30, max_samples=25
        )
        all_sample_parts.extend(parts)

    if not all_sample_parts:
        raise HTTPException(status_code=500, detail="ìƒ˜í”Œ ìƒì„± ì‹¤íŒ¨")

    # â”€â”€ NEW: ì´ë¯¸ì§€ ì €ì¥ â”€â”€
    image_url = None
    if image:
        ext = os.path.splitext(image.filename)[1] or ".png"
        filename = f"{uuid4().hex}{ext}"
        dest = os.path.join(IMAGE_FOLDER, filename)
        with open(dest, "wb") as img_f:
            img_f.write(await image.read())
        image_url = f"/images/{filename}"

    # ElevenLabs API í˜¸ì¶œ
    voice_response = create_voice_model_api(
        name=name,
        description=description,
        sample_file_paths=all_sample_parts
    )
    voice_id = voice_response.get("voice_id")
    if not voice_id:
        raise HTTPException(status_code=500, detail="voice_id ë°˜í™˜ ëˆ„ë½")

    # â”€â”€ DB ì €ì¥ (image_url í¬í•¨) â”€â”€
    with get_db_cursor() as curs:
        curs.execute(
            """
            INSERT INTO voice_models
                (voice_id, name, description, image_url)
            VALUES (%s, %s, %s, %s)
            RETURNING id;
            """,
            (voice_id, name, description, image_url),
        )
        inserted_id = curs.fetchone()[0]

    background_tasks.add_task(delete_temp_files, temp_paths)

    return JSONResponse(
        {
            "message": "ë³´ì´ìŠ¤ ëª¨ë¸ ìƒì„± ì™„ë£Œ",
            "db_id": inserted_id,
            "voice_id": voice_id,
            "name": name,
            "description": description,
            "image_url": image_url,    # â† NEW: ë°˜í™˜
        },
        status_code=200
    )


@app.get("/voice-models")
async def list_voice_models():
    with get_db_cursor() as curs:
        curs.execute("""
            SELECT id, name, voice_id, description, image_url
            FROM voice_models
            ORDER BY id;
        """)
        rows = curs.fetchall()

    models = []
    for db_id, name, vid, desc, img in rows:
        models.append({
            "db_id":       db_id,
            "name":        name,
            "voice_id":    vid,
            "description": desc,
            "image_url":   img,       # â† NEW: í¬í•¨
        })
    return JSONResponse(content=models)

def generate_waveform_png(audio_path: str, out_path: str, width_px: int, height_px: int = 100):
    y, sr = librosa.load(audio_path, sr=22050, mono=True)
    if len(y) == 0:
        y = np.zeros(22050//2)
    samples_per_px = max(1, len(y) // width_px)
    peaks = []
    for i in range(width_px):
        s = i * samples_per_px
        e = min(len(y), s + samples_per_px)
        amp = float(np.max(np.abs(y[s:e]))) if s < len(y) else 0.0
        peaks.append(amp)
    maxamp = max(peaks) or 1.0
    peaks = [p / maxamp for p in peaks]

    img = Image.new("RGB", (width_px, height_px), "#FFFFFF")
    draw = ImageDraw.Draw(img)
    mid = height_px / 2.0
    for x, p in enumerate(peaks):
        h = p * (height_px * 0.9)
        y0 = int(mid - h/2); y1 = int(mid + h/2)
        draw.line((x, y0, x, y1), fill="#007bff", width=1)
    img.save(out_path, format="PNG")