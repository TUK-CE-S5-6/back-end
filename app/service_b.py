import os
import time
import psycopg2
import logging
import requests
import librosa
import shutil
import subprocess
import json
from contextlib import contextmanager
from typing import Optional, List

import soundfile as sf  # íƒ€ì„ ìŠ¤íŠ¸ë ˆì¹­ í›„ ì˜¤ë””ì˜¤ ì €ì¥ìš©
import tensorflow as tf
from fastapi import FastAPI, UploadFile, File, HTTPException, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from pydub import AudioSegment
from pydub.silence import detect_nonsilent

# ----------------------------
# ê¸°ë³¸ ì„¤ì • ë° í™˜ê²½ ë³€ìˆ˜
# ----------------------------
logging.basicConfig(level=logging.DEBUG)

AUDIO_FOLDER = "extracted_audio"
os.makedirs(AUDIO_FOLDER, exist_ok=True)
CUSTOM_TTS_FOLDER = os.path.join(AUDIO_FOLDER, "custom_tts")
os.makedirs(CUSTOM_TTS_FOLDER, exist_ok=True)
VOICE_MODEL_FOLDER = "voice_models"
os.makedirs(VOICE_MODEL_FOLDER, exist_ok=True)

# FastAPI ì•± ìƒì„±
app = FastAPI()

DB_NAME = "test"
DB_USER = "postgres"
DB_PASSWORD = "1234"
DB_HOST = "localhost"
DB_PORT = "5433"

ELEVENLABS_API_KEY = "eleven-key"
ELEVENLABS_BASE_URL = "https://api.elevenlabs.io/v1"

# CORS ì„¤ì •
origins = ["http://localhost:3000"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ----------------------------
# Pydantic ëª¨ë¸
# ----------------------------
class CustomTTSRequest(BaseModel):
    tts_id: Optional[int] = None
    voice_id: str
    text: str

# ----------------------------
# PostgreSQL ì—°ê²° í•¨ìˆ˜
# ----------------------------
def get_connection():
    conn = psycopg2.connect(
        dbname=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD,
        host=DB_HOST,
        port=DB_PORT
    )
    return conn

@contextmanager
def get_db_cursor():
    conn = get_connection()
    try:
        curs = conn.cursor()
        yield curs
        conn.commit()
    except Exception as e:
        conn.rollback()
        raise e
    finally:
        curs.close()
        conn.close()

# ----------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ----------------------------
def ensure_folder(path: str):
    os.makedirs(path, exist_ok=True)

def delete_temp_files(file_paths: List[str]):
    for fp in file_paths:
        try:
            if os.path.exists(fp):
                if os.path.isdir(fp):
                    shutil.rmtree(fp, ignore_errors=True)
                    logging.info(f"Deleted folder: {fp}")
                else:
                    os.remove(fp)
                    logging.info(f"Deleted file: {fp}")
        except Exception as e:
            logging.error(f"Failed to delete {fp}: {e}")

def run_spleeter_subprocess(input_path: str, output_folder: str):
    command = [
        "python", "-m", "spleeter.separator",
        "separate_to_file", input_path, output_folder,
        "-p", "spleeter:2stems"
    ]
    logging.info("Spleeter subprocess command: " + " ".join(command))
    result = subprocess.run(command, capture_output=True, text=True)
    if result.returncode != 0:
        raise Exception("Spleeter subprocess failed: " + result.stderr)
    else:
        logging.info(result.stdout)

def find_spleeter_vocals(base_folder: str, base_name: str):
    vocals_candidates = []
    bgm_candidates = []
    primary_folder = os.path.join(base_folder, base_name)
    if os.path.exists(primary_folder):
        for root, dirs, files in os.walk(primary_folder):
            if "vocals.wav" in files:
                vocals_candidates.append(os.path.join(root, "vocals.wav"))
            if "accompaniment.wav" in files:
                bgm_candidates.append(os.path.join(root, "accompaniment.wav"))
    alternate_folder = os.path.join(base_folder, f"{base_name}_audio")
    if os.path.exists(alternate_folder):
        for root, dirs, files in os.walk(alternate_folder):
            if "vocals.wav" in files:
                vocals_candidates.append(os.path.join(root, "vocals.wav"))
            if "accompaniment.wav" in files:
                bgm_candidates.append(os.path.join(root, "accompaniment.wav"))
    if not vocals_candidates or not bgm_candidates:
        raise FileNotFoundError(
            f"âŒ '{base_folder}' ë‚´ì— '{base_name}' ë˜ëŠ” '{base_name}_audio' í´ë”ì—ì„œ í•„ìš”í•œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!"
        )
    # ì—¬ëŸ¬ ê°œ ìˆë”ë¼ë„ ì²« ë²ˆì§¸ í•­ëª©ë§Œ ì„ íƒí•´ì„œ ë°˜í™˜
    return vocals_candidates[0], bgm_candidates[0]


def split_audio(input_path: str, output_dir: str, max_size_mb: int = 10):
    ensure_folder(output_dir)
    try:
        audio = AudioSegment.from_file(input_path)
        threshold = audio.dBFS - 16
        nonsilent_ranges = detect_nonsilent(audio, min_silence_len=500, silence_thresh=threshold, seek_step=1)
        parts = []
        for idx, (start, end) in enumerate(nonsilent_ranges):
            if end - start < 1000:
                continue
            segment = audio[start:end]
            part_path = os.path.join(output_dir, f"part_{idx}.mp3")
            segment.export(part_path, format="mp3", bitrate="192k")
            parts.append(part_path)
        logging.info(f"ğŸ”¹ ë¶„í• ëœ íŒŒì¼ ê°œìˆ˜: {len(parts)}")
        max_samples = 25
        if len(parts) > max_samples:
            indices = [int(i * (len(parts) - 1) / (max_samples - 1)) for i in range(max_samples)]
            parts = [parts[i] for i in indices]
            logging.info(f"ğŸ”¹ ìƒ˜í”Œ ìˆ˜ê°€ ë§ì•„ ê· ì¼í•˜ê²Œ {max_samples}ê°œë¡œ ì¶•ì†Œí•¨")
        return parts
    except Exception as e:
        logging.error(f"âŒ ì˜¤ë””ì˜¤ ë¶„í•  ì‹¤íŒ¨: {str(e)}")
        return []

def merge_nonsilent_audio_improved(
    input_path: str,
    output_dir: str,
    min_silence_len: int = 500,
    silence_thresh: float = None,
    output_filename: str = "merged_sample.mp3",
    fade_duration: int = 200
):
    ensure_folder(output_dir)
    try:
        audio = AudioSegment.from_file(input_path)
        if silence_thresh is None:
            silence_thresh = audio.dBFS - 16
        nonsilent_ranges = detect_nonsilent(
            audio,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh,
            seek_step=1
        )
        merged_audio = AudioSegment.empty()
        for start, end in nonsilent_ranges:
            if end - start < 1000:
                continue
            segment = audio[start:end]
            segment = segment.fade_in(fade_duration).fade_out(fade_duration)
            merged_audio += segment
        output_path = os.path.join(output_dir, output_filename)
        merged_audio.export(output_path, format="mp3", bitrate="192k")
        logging.info(f"ğŸ”¹ ë³‘í•©ëœ íŒŒì¼ ìƒì„±: {output_path}")
        return output_path
    except Exception as e:
        logging.error(f"âŒ ë³‘í•© ì‹¤íŒ¨: {str(e)}")
        return None

def split_merged_audio(
    merged_path: str,
    output_dir: str,
    max_duration_sec: int = 30,
    max_samples: int = 25
):
    ensure_folder(output_dir)
    try:
        audio = AudioSegment.from_file(merged_path)
        duration_ms = len(audio)
        max_duration_ms = max_duration_sec * 1000
        parts = []
        if duration_ms <= max_duration_ms:
            parts.append(merged_path)
        else:
            num_parts = (duration_ms + max_duration_ms - 1) // max_duration_ms
            for i in range(num_parts):
                start = i * max_duration_ms
                end = min((i + 1) * max_duration_ms, duration_ms)
                segment = audio[start:end]
                part_path = os.path.join(output_dir, f"merged_part_{i}.mp3")
                segment.export(part_path, format="mp3", bitrate="192k")
                parts.append(part_path)
        if len(parts) > max_samples:
            indices = [
                int(i * (len(parts) - 1) / (max_samples - 1))
                for i in range(max_samples)
            ]
            parts = [parts[i] for i in indices]
            logging.info(f"ğŸ”¹ ë³‘í•© ìƒ˜í”Œ ìˆ˜ê°€ ë§ì•„ ê· ì¼í•˜ê²Œ {max_samples}ê°œë¡œ ì¶•ì†Œí•¨")
        return parts
    except Exception as e:
        logging.error(f"âŒ ë³‘í•© í›„ ë¶„í•  ì‹¤íŒ¨: {str(e)}")
        return []

def create_voice_model_api(name: str, description: str, sample_file_paths: List[str]):
    url = f"{ELEVENLABS_BASE_URL}/voices/add"
    headers = {"xi-api-key": ELEVENLABS_API_KEY}
    data = {"name": name, "description": description}
    files = []
    for path in sample_file_paths:
        try:
            f = open(path, "rb")
        except Exception as e:
            logging.error(f"íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨ ({path}): {str(e)}")
            continue
        files.append(("files", (os.path.basename(path), f, "audio/mpeg")))
    try:
        response = requests.post(url, headers=headers, data=data, files=files)
        response.raise_for_status()
        return response.json()
    finally:
        for _, file_tuple in files:
            file_tuple[1].close()

def adjust_tts_duration(file_path: str, desired_duration: float) -> float:
    y, sr = librosa.load(file_path, sr=None)
    current_duration = librosa.get_duration(y=y, sr=sr)
    rate = current_duration / desired_duration
    rate = min(max(rate, 0.85), 1.15)
    logging.info(
        f"adjust_tts_duration - í˜„ì¬ ê¸¸ì´: {current_duration:.2f} sec, "
        f"ì›í•˜ëŠ” ê¸¸ì´: {desired_duration:.2f} sec, ì ìš© ë¹„ìœ¨: {rate:.2f}"
    )
    y_stretched = librosa.effects.time_stretch(y, rate=rate)
    sf.write(file_path, y_stretched, sr)
    new_duration = librosa.get_duration(y=y_stretched, sr=sr)
    logging.info(f"adjust_tts_duration - ì¡°ì • í›„ ê¸¸ì´: {new_duration:.2f} sec")
    return new_duration

# ----------------------------
# FastAPI ì—”ë“œí¬ì¸íŠ¸
# ----------------------------
app.mount("/videos", StaticFiles(directory="uploaded_videos"), name="videos")
app.mount("/extracted_audio", StaticFiles(directory="extracted_audio"), name="audio")

@app.get("/")
def read_root():
    return {"message": "Hello from Service B (TTS Creation)!"}

@app.post("/separate-audio")
async def separate_audio(file: UploadFile = File(...)):
    try:
        original_name = os.path.splitext(file.filename)[0]
        base_name = (
            original_name[:-len("_audio")]
            if file.filename.endswith("_audio")
            else original_name
        )
        input_path = os.path.join(AUDIO_FOLDER, f"{base_name}.mp3")
        with open(input_path, "wb") as f:
            f.write(await file.read())
        logging.info(f"ì…ë ¥ ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {input_path}")

        from spleeter.separator import Separator
        separator = Separator("spleeter:2stems")
        separator.separate_to_file(input_path, AUDIO_FOLDER)
        logging.info("Spleeter ë¶„ë¦¬ ì‹¤í–‰ ì™„ë£Œ")

        vocals_path, bgm_path = find_spleeter_vocals(AUDIO_FOLDER, base_name)
        logging.info(f"ë¶„ë¦¬ëœ íŒŒì¼ ì°¾ìŒ: vocals={vocals_path}, bgm={bgm_path}")

        return JSONResponse(
            content={
                "message": "Spleeter ë¶„ë¦¬ ì™„ë£Œ",
                "vocals_path": vocals_path,
                "bgm_path": bgm_path
            },
            status_code=200
        )
    except Exception as e:
        logging.error(f"Spleeter ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"Spleeter ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
        )

@app.post("/generate-tts-from-stt")
async def generate_tts_from_stt(data: dict):
    try:
        video_id = data.get("video_id")
        if video_id is None:
            raise HTTPException(status_code=400, detail="video_idê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        with get_db_cursor() as curs:
            curs.execute(
                """
                SELECT t.translation_id, t.text, tr.start_time, tr.end_time
                FROM translations t
                JOIN transcripts tr ON t.transcript_id = tr.transcript_id
                WHERE tr.video_id = %s;
                """,
                (video_id,)
            )
            translations = curs.fetchall()
            if not translations:
                raise HTTPException(
                    status_code=404, detail="ë²ˆì—­ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                )
            tts_output_dir = os.path.join(AUDIO_FOLDER, f"{video_id}_tts")
            ensure_folder(tts_output_dir)
            selected_voice_id = "5Af3x6nAIWjF6agOOtOz"
            for translation_id, text, start_time, end_time in translations:
                try:
                    url = (
                        f"{ELEVENLABS_BASE_URL}/text-to-speech/"
                        f"{selected_voice_id}?output_format=mp3_44100_128"
                    )
                    headers = {
                        "xi-api-key": ELEVENLABS_API_KEY,
                        "Content-Type": "application/json",
                    }
                    payload = {
                        "text": text,
                        "model_id": "eleven_multilingual_v2",
                    }
                    response = requests.post(url, headers=headers, json=payload)
                    if response.status_code != 200:
                        raise Exception(
                            f"ElevenLabs TTS ìƒì„± ì‹¤íŒ¨: {response.text}"
                        )
                    audio_content = response.content

                    tts_audio_path = os.path.join(
                        tts_output_dir, f"{translation_id}.mp3"
                    )
                    with open(tts_audio_path, "wb") as tts_file:
                        tts_file.write(audio_content)

                    current_duration = librosa.get_duration(path=tts_audio_path)
                    desired_duration = float(end_time) - float(start_time)

                    # ë¡œê·¸ ì¶”ê°€: TTS í…ìŠ¤íŠ¸, ì›ë³¸ ê¸¸ì´, ì›í•˜ëŠ” ê¸¸ì´ ì¶œë ¥
                    logging.info(f"TTS í…ìŠ¤íŠ¸: {text}")
                    logging.info(
                        f"ì›ë³¸ TTS ê¸¸ì´: {current_duration:.2f} sec, "
                        f"ì›í•˜ëŠ” ê¸¸ì´: {desired_duration:.2f} sec"
                    )

                    new_duration = adjust_tts_duration(
                        tts_audio_path, desired_duration
                    )

                    # ë¡œê·¸ ì¶”ê°€: ì¡°ì • í›„ ê¸¸ì´ ì¶œë ¥
                    logging.info(
                        f"ì¡°ì • í›„ TTS ê¸¸ì´: {new_duration:.2f} sec "
                        f"(ì›ë³¸: {current_duration:.2f} sec "
                        f"â†’ ì¡°ì •: {new_duration:.2f} sec)"
                    )

                    curs.execute(
                        """
                        INSERT INTO tts
                        (translation_id, file_path, voice, start_time, duration)
                        VALUES (%s, %s, %s, %s, %s);
                        """,
                        (
                            translation_id,
                            tts_audio_path,
                            selected_voice_id,
                            float(start_time),
                            float(new_duration),
                        ),
                    )
                except Exception as e:
                    logging.error(f"TTS ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return JSONResponse(
            content={"message": "TTS ìƒì„± ì™„ë£Œ"}, status_code=200
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"TTS ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")


@app.post("/generate-tts")
async def generate_tts_custom(request: CustomTTSRequest):
    try:
        conn = get_connection()
        curs = conn.cursor()
        with get_db_cursor() as curs:
            if request.tts_id is not None:
                curs.execute(
                    """
                    SELECT translation_id, file_path
                    FROM tts
                    WHERE tts_id = %s;
                    """,
                    (request.tts_id,),
                )
                row = curs.fetchone()
                if not row:
                    raise HTTPException(
                        status_code=404,
                        detail="í•´ë‹¹ tts_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    )
                translation_id, tts_audio_path = row
                curs.execute(
                    """
                    UPDATE translations
                    SET text = %s
                    WHERE translation_id = %s;
                    """,
                    (request.text, translation_id),
                )
                try:
                    url = (
                        f"{ELEVENLABS_BASE_URL}/text-to-speech/"
                        f"{request.voice_id}?output_format=mp3_44100_128"
                    )
                    headers = {
                        "xi-api-key": ELEVENLABS_API_KEY,
                        "Content-Type": "application/json",
                    }
                    payload = {
                        "text": request.text,
                        "model_id": "eleven_multilingual_v2",
                    }
                    response = requests.post(url, headers=headers, json=payload)
                    if response.status_code != 200:
                        raise Exception(
                            f"ElevenLabs TTS ìƒì„± ì‹¤íŒ¨: {response.text}"
                        )
                    audio_content = response.content
                    with open(tts_audio_path, "wb") as tts_file:
                        tts_file.write(audio_content)
                    duration = librosa.get_duration(path=tts_audio_path)
                    curs.execute(
                        """
                        UPDATE tts
                        SET voice = %s, duration = %s
                        WHERE tts_id = %s;
                        """,
                        (request.voice_id, duration, request.tts_id),
                    )
                except Exception as e:
                    raise HTTPException(
                        status_code=500,
                        detail=f"ElevenLabs TTS ìƒì„± ì‹¤íŒ¨: {str(e)}",
                    )
            else:
                timestamp = int(time.time())
                tts_audio_path = os.path.join(
                    CUSTOM_TTS_FOLDER, f"tts_{timestamp}.mp3"
                )
                try:
                    url = (
                        f"{ELEVENLABS_BASE_URL}/text-to-speech/"
                        f"{request.voice_id}?output_format=mp3_44100_128"
                    )
                    headers = {
                        "xi-api-key": ELEVENLABS_API_KEY,
                        "Content-Type": "application/json",
                    }
                    payload = {
                        "text": request.text,
                        "model_id": "eleven_multilingual_v2",
                    }
                    response = requests.post(url, headers=headers, json=payload)
                    if response.status_code != 200:
                        raise Exception(
                            f"ElevenLabs TTS ìƒì„± ì‹¤íŒ¨: {response.text}"
                        )
                    audio_content = response.content
                    with open(tts_audio_path, "wb") as tts_file:
                        tts_file.write(audio_content)
                except Exception as e:
                    raise HTTPException(
                        status_code=500,
                        detail=f"ElevenLabs TTS ìƒì„± ì‹¤íŒ¨: {str(e)}",
                    )
                curs.execute(
                    """
                    INSERT INTO translations (text, language)
                    VALUES (%s, %s)
                    RETURNING translation_id;
                    """,
                    (request.text, "en"),
                )
                translation_id = curs.fetchone()[0]
                duration = librosa.get_duration(path=tts_audio_path)
                curs.execute(
                    """
                    INSERT INTO tts
                    (translation_id, file_path, voice, start_time, duration)
                    VALUES (%s, %s, %s, %s, %s)
                    RETURNING tts_id;
                    """,
                    (
                        translation_id,
                        tts_audio_path,
                        request.voice_id,
                        0.0,
                        duration,
                    ),
                )
                request.tts_id = curs.fetchone()[0]
        conn.commit()
        curs.close()
        conn.close()
        tts_file_url = tts_audio_path.replace(AUDIO_FOLDER, "/extracted_audio")
        return JSONResponse(
            content={
                "message": "TTS ìƒì„± ì™„ë£Œ",
                "file_url": tts_file_url,
                "tts_id": request.tts_id,
            },
            status_code=200,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"TTS ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")


@app.post("/create-voice-model")
async def create_voice_model(
    background_tasks: BackgroundTasks,
    name: str = Form(...),
    description: str = Form(...),
    files: List[UploadFile] = File(...),
):
    """
    ì—…ë¡œë“œëœ ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ì„œ,
    ê° íŒŒì¼ì— ëŒ€í•´ Spleeterë¡œ ë³´ì»¬(ìŒì„±)ë§Œ ë¶„ë¦¬í•œ í›„,
    ë¶„ë¦¬ëœ ë³´ì»¬ ìŒì›ì„ ê¸°ë°˜ìœ¼ë¡œ ë¬´ìŒ êµ¬ê°„ì„ ì œê±°í•˜ê³  ë³‘í•©/ë¶„í• í•˜ì—¬
    ìµœëŒ€ 25ê°œì˜ ìƒ˜í”Œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ ìƒ˜í”Œ íŒŒì¼ë“¤ì„ ElevenLabs APIì— ì „ë‹¬í•˜ì—¬ ë³´ì´ìŠ¤ ëª¨ë¸(í´ë¡ )ì„ ìƒì„±í•˜ê³ ,
    ìƒì„±ëœ ëª¨ë¸ ì •ë³´ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤.
    ì‘ì—… ì™„ë£Œ í›„ ì„ì‹œ íŒŒì¼ë“¤ì€ BackgroundTasksë¥¼ ì´ìš©í•˜ì—¬ ì‚­ì œë©ë‹ˆë‹¤.
    
    **íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.**
    """
    all_sample_parts = []
    temp_paths = []

    MAX_FILE_SIZE = 10 * 1024 * 1024

    for file in files:
        file.file.seek(0, os.SEEK_END)
        size = file.file.tell()
        file.file.seek(0)
        if size > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=400,
                detail=f"íŒŒì¼ {file.filename}ì˜ í¬ê¸°ê°€ 10MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤."
            )

        original_name = os.path.splitext(file.filename)[0]
        base_name = (
            original_name[:-len("_audio")]
            if file.filename.endswith("_audio")
            else original_name
        )

        # íŒŒì¼ëª…ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì‹œê°„ ì œê±°)
        original_path = os.path.join(AUDIO_FOLDER, f"{base_name}.mp3")
        logging.info(f"ğŸ“¥ íŒŒì¼ ì €ì¥ ì‹œì‘: {file.filename}")
        with open(original_path, "wb") as f:
            f.write(await file.read())
        temp_paths.append(original_path)

        # Spleeter ì‹¤í–‰
        try:
            from spleeter.separator import Separator
            separator = Separator("spleeter:2stems")
            separator.separate_to_file(original_path, AUDIO_FOLDER)
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Spleeter ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
            )

        # vocals.wav íŒŒì¼ ì°¾ê¸°
        vocal_path, _ = find_spleeter_vocals(AUDIO_FOLDER, base_name)

        # ê³ ì •ëœ ì´ë¦„ìœ¼ë¡œ ë³´ì»¬ íŒŒì¼ ì €ì¥
        fixed_vocal_path = os.path.join(AUDIO_FOLDER, f"{base_name}_vocals.wav")
        shutil.move(vocal_path, fixed_vocal_path)
        temp_paths.append(fixed_vocal_path)

        # Spleeterê°€ ìƒì„±í•œ ì›ë³¸ í´ë” ì‚­ì œ
        folder_primary = os.path.join(AUDIO_FOLDER, base_name)
        if os.path.exists(folder_primary):
            temp_paths.append(folder_primary)
            shutil.rmtree(folder_primary, ignore_errors=True)

        folder_alternate = os.path.join(AUDIO_FOLDER, f"{base_name}_audio")
        if os.path.exists(folder_alternate):
            temp_paths.append(folder_alternate)
            shutil.rmtree(folder_alternate, ignore_errors=True)

        # ë³‘í•© ë° ë¶„í• 
        merge_dir = os.path.join(AUDIO_FOLDER, f"{base_name}_merged")
        os.makedirs(merge_dir, exist_ok=True)
        temp_paths.append(merge_dir)
        merged_sample_path = merge_nonsilent_audio_improved(
            fixed_vocal_path, merge_dir,
            output_filename="merged_sample.mp3",
            fade_duration=200
        )
        if not merged_sample_path:
            raise HTTPException(
                status_code=500, detail="ë³‘í•© íŒŒì¼ ìƒì„± ì‹¤íŒ¨"
            )

        split_dir = os.path.join(AUDIO_FOLDER, f"{base_name}_split")
        os.makedirs(split_dir, exist_ok=True)
        temp_paths.append(split_dir)
        MAX_MERGED_DURATION_SEC = 30
        sample_parts = split_merged_audio(
            merged_sample_path, split_dir,
            max_duration_sec=MAX_MERGED_DURATION_SEC,
            max_samples=25
        )
        if not sample_parts:
            raise HTTPException(
                status_code=500, detail="ë³‘í•© í›„ ë¶„í•  ì‹¤íŒ¨"
            )

        all_sample_parts.extend(sample_parts)

    if not all_sample_parts:
        raise HTTPException(
            status_code=500, detail="ìƒ˜í”Œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨"
        )

    # ElevenLabs API í˜¸ì¶œ
    voice_response = create_voice_model_api(
        name=name,
        description=description,
        sample_file_paths=all_sample_parts
    )
    voice_id = voice_response.get("voice_id")
    if not voice_id:
        raise Exception("ë³´ì´ìŠ¤ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: voice_idê°€ ë°˜í™˜ë˜ì§€ ì•ŠìŒ")
    logging.info(f"âœ… ë³´ì´ìŠ¤ ëª¨ë¸ ìƒì„± ì™„ë£Œ: {voice_id}")

    with get_db_cursor() as curs:
        curs.execute(
            """
            INSERT INTO voice_models (voice_id, name, description)
            VALUES (%s, %s, %s)
            RETURNING id;
            """,
            (voice_id, name, description),
        )
        inserted_id = curs.fetchone()[0]
    logging.info(f"ğŸ“Œ DBì— voice_models í…Œì´ë¸”ì— ì €ì¥ ì™„ë£Œ (id: {inserted_id})")

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    background_tasks.add_task(delete_temp_files, temp_paths)

    return JSONResponse(
        content={
            "message": "ë³´ì´ìŠ¤ ëª¨ë¸ ìƒì„± ì™„ë£Œ",
            "voice_id": voice_id,
            "name": name,
            "description": description,
            "db_id": inserted_id,
        },
        status_code=200
    )
